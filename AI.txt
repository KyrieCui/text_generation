Previously, we might use machine learning in a few sub-components of a system. Now we actually use machine learning to replace entire sets of systems, rather than trying to make a better machine learning model for each of the pieces. Dr. Jeff Dean (Lead of Google AI team, born 1968) Abstract This chapter explores the first and foremost AI component and technologyâ€”machine learning (ML). We explore how humans learn and three major machine learning models: supervised learning, unsupervised learning, and reinforcement learning. We also study how the human brain works to think and learnâ€”biological neural networks which lead to the design of artificial neural networks (ANN)â€”mathematical and computational counterparts to simulate human memory, learning, and thinking processes. To illustrate different types and models of memory storage, thinking and learning operations, we introduce four basic types of ANNs: (1) Auto-associative network for associative learning; (2) Hopfield network for memory storage and retrieval; (3) Feedforward backpropagation neural network for supervised learning; and (4) Actor-critic multi-agent-based model for reinforcement learning. Algorithms and models pertaining to microscopic AI cover five major components: Machine learning (ML) Data mining (DM) Computer vision (CV) Natural language processing (NLP) Ontological-based search engine (OSE). We begin with machine learning (ML). Machine learning is the foremost and fundamental AI component. Many AI scientists, the author included, believe that any good AI application should inherit certain machine learning skills or capabilities; it should NOT claim to be an intelligent system if otherwise. In other words, a sophisticated chess-playing system (robot) without machine learning skills can only be regarded as ordinary computer system without any intelligence, letâ€™s alone to be an expert system (Fig. 3.1). So, what is Machine Learning? 3.1 The von Neumann Machine Anyone who took computer fundamental courses knew the basic architecture of the computer system comes from von Neumann Architecture , also known as the von Neumann Model. It was a computer architecture proposed by polymath Prof. John von Neumann (1903â€“1957) in 1945 (Rojas and Hashagen 2000) based on Sir Alan Turingâ€™s work on Turing Machine . The design was published in a document called First Draft of a Report on the EDVAC . It 3 Machine Learning 43 described the first stored-program computer. The early computers such as ENIAC were hard-wired to do a single task. If the computer had to perform a different task, it required to rewire with a tedious process. A stored-program computer is a general-purpose computer built to run different programs. The von Neumann Machine can be considered a prototype of the modern computer system. Figure 3.2 illustrates the basic components of von Neumann Machine which consists of Central processing unit (CPU)â€”system brain consists of system control unit, basic arithmetic, and logical unit. Memory unitâ€”data and information storage . Input and output unitsâ€”data input (e.g. keyboard) and output (e.g. screen). Computer systems, regardless of speed or network, vary among supercomputers, mainframes, workstations, PCs, and mobile devices we use today; their basic architectures are all inherited from the blueprint of von Neumann Machine . Are theyintelligent machines ? Why or why not? Letâ€™s take a look at two scenarios of computer systems applying to our daily activities. 3.2 Case 1â€“7â€”Day Weather Forecast System First, look at a typical 7-Day Weather Forecast System. It makes no difference where you live, we all know what the weather forecast is. In fact, one of the major computer system applications (supercomputer system, in particular) is weather forecasting . Major weather forecast systems at present are called Numerical Weather Prediction (NWP) (Kalnay 2003). A typical NWP uses weather observations (such as temperature, air pressure, wind speed, and directions) of global grid points from different atmospheric levels as initial conditions. Numerical weather prediction is calculated by using fluid dynamics, thermodynamics equations, and Newtonâ€™s laws of motion equations to forecast weather components such as air pressure, temperature, humidity, wind speed, and directions of every grid point for the future 168 h (7 days), with an overall accuracy of over 80â€“85%. Figure 3.3 shows a typical 7-day weather forecast results. This forecast system is complex and powerful without argument, and it is a very typical von Neumann Machine . But is there Intelligence ? Can it learn ? Can it improve by itself ? The answer is certainty no. 3 Machine Learning 45 This system crushes with global grid point inputs, runs the forecast program, and produces forecast results regardless of its sophistication. The machine itself never learns or becomes smarter even though it has forecasts for years. 3.3 Case 2â€”AlphaGO AlphaGo (DeepMind 2020) is an AI-based computer program that plays the board game Go. AlphaGo was developed by DeepMind Technologies in 2015 and acquired by Google. Go is an abstract strategy board game invented by the Chinese over 2500 years ago. It is believed to be the most complicated board game in human history. The Go game (Pumperla and Ferguson 2019) is played by 2 players. The chess pieces are called stones . One player uses white stones and the other uses black. The players take turns placing the stones on vacant intersection points of the chessboard. Once placed on the board, the stones may not be moved, but are to be removed from the board if captured . Capture occurs when a stone or group of stones is/are surrounded by opposing stones on all adjacent orthogonal points. The game proceeds until neither player wishes to make another move. When a game concludes, the winner is determined by counting each playerâ€™s surrounded territory along with the captured stones. It is different from the standard von Neumann Machine where an AI-based chess-playing system has a unique feature such that it can learn from the game. In other words, just like playing a game with an experienced chess master . When we play chess each time, the chess master will use his/her experience and knowledge to a greater extent. The most important fact is that he/she will improve his/her own chess-playing strategies to learn and predict our moves, to revise his/her own strategies and increase winning possibilities. This is what we call machine learningâ€”intelligence (Fig. 3.4). 3.4 How Humans Learn? What is Machine Learning ? To answer this question, letâ€™s begin with How can humans learn? Maybe it is perplexing to think about the approach. Letâ€™s think of how we train children to learn. For example, matching a simple shape with a name as in Fig. 3.5. Machine Learning 47 The method is simple but is commonly used by humans to learn an associating concept/idea (e.g. shape) with another concept/idea (e.g. shape name). We call this learning method associative learning . Frankly, associative learning (Wills 2005) is a distinctly important learning method that occupies almost 80% of our entire learning life which includes Languages; Translation; Pattern and objective association; Concept and idea association. Latest cognitive science believes that most low-level sensations such as touch, smell, and vision are all related to associative learning . So, one might wonder: What are the characteristics of this type of learning ? This type of machine learning is characterized generally as learning by example . 3.5 Three Pillars of Machine Learning Methods There are many different types of learning methods of our lives (Alpaydin 2016) that can be categorized into three major methods as illustrated in Fig. 3.6: Supervised learning, Unsupervised learning, and Reinforcement learning. These learning methods consolidate with all various types of learning objectives and activities which include Pattern association and recognition (Bishop 2006), Object (2D, 3D) recognition and vision (Davies 2017), Concept learning and memorization (Gluck et al. 2016), Logical thinking and decision-making (Dettmer 2007), and High-level mental thinking and deduction process (Haber 2020). It is important that although these learning processes are separate issues technically, humans combine them throughout their overall daily learning, knowledge memory, and recalling processes subconsciously. Contemporary neuroscience (McNamara 2019) even believes humans sleep and dream not only to regain health and conscious mind, but more importantly to provide mechanisms for our brainsâ€™ neural networks to reorganize memory and knowledge we experienced and learnt during interactions with the environment in the daytime. 3.6 Supervised Learning method. It is characterized by learning of example + outcome in the sense Supervised Learning (Alpaydin 2016) is the basic type of machine learning that no matter what the kind of learning objective is (e.g. pattern matching and memory of words), the learning is performed by presenting sample input + target output pairs. Typical examples are Pattern association with words. Concept association with meanings. Concept and meaning memorization. Logical deduction (if then â€¦ else). Logical induction. Letâ€™s use human face recognition as an example. As we know, human is competent to recognize human faces. The question is: How can we build a machine to mimic humans to recognize human faces? Technically speaking, human face recognition (Li and Jain 2005) is a very primitive and basic supervised learning activity. Without training our brain on how to memorize a specific human face as per its name (a kind of patternâ€“ name association), how can we recognize a familiar human face on the street? Another important feature is that such activity is usually performed subconsciously (or we can say hard-coded ) in our brains. For example, whenever we see anyone, our brain will try to recognize his/her with our memories to examine whether we know him/her within seconds. Latest works on cognitive science and neuroscience revealed that human is the best to perform such amazing job because we can extract important features subconsciously from a human face using the so-called facial landmarks and their relationship altogether as displayed to recognize nose, eyes, mouth, and ears separately. These theories inspire AI R&D in facial recognition to be studied in the following chapter (Fig. 3.7). 3.7 Unsupervised Learning Unsupervised learning (Celebi and Aydin 2016) is a type of machine learning that looks for previous undetected patterns in a dataset of no pre-existing labels with minimum human supervision which is in contrast to supervised learning that usually uses human-labeled data. It is also known as self-organization that allows probability density modeling over inputs. In other words, unsupervised learning can be regarded as a kind of self-learning characterized without any specific target(s) or correct answers. Typical examples include Pattern clustering, Figure-ground segmentation, and High-level mental process. 3.7.1 Pattern Clustering Pattern clustering (Hennig et al. 2015), or clustering , is the task of grouping a set of objects situated in the same group (called a cluster ) that are more similar (or close) to each other than to those in other groups (clusters). Pattern clustering includes object and pattern clustering and the auto-grouping process. It is believed that the inherited and natural process of human learning capacity can be achieved without prior knowledge. Apart from visual pattern clustering, nonvisual and mental clustering concepts and ideas also fall into this learning category. Figure 3.8 shows a typical example of dots patch pattern clustering into two distinct clusters. In the coming section, we will reveal how we can train our brains to perform this process. 3.7.2 Figure-Ground Segmentation Figure-ground segmentation explores the way how we differentiate an object from its background. It has more fundamental visual and unsupervised learning realized subconsciously in our minds. Figure 3.9 shows the famous visual psychology Rubin-vase experiment, the so-called Gestalt psycholog y (Koffka 2014). Gestalt psychologists emphasize that organisms perceive entire patterns or configurations, not merely on individual components. In this experiment, Gestalt psychologists maintain that human can either identify a vase or two human face profiles but not two items simultaneously. It is different from the recognition of an object such as human face mentioned in supervised learning. This learning machine must have a set of objectsâ€™ databank (e.g. human face databank in face recognition problem) to learn or compare with. Figure-ground segmentation is considered as a typical kind of unsupervised learning in machine learning where there should be no target-object to match or compare with. In other words, a typical figureground segmentation engine can automatically extract an object from the scene (background) before it recognizes what the object is. 3.7.3 High-Level Mental Process High-level mental process such as book reading is a kind of unsupervised learning in the sense that during the process, our mind tries to conceptualize words, clauses, and passages into concept and idea clusters , compares with what we had learnt from memory, and stores them subconsciously as new knowledge . In many typical cases, unsupervised learning is performed in our mind subconsciously and automatically. Many primitive visual psychologies including Gestalt psychology are highly related to human-inherited unsupervised visual learning capability. The latest psychology development also reveals that unsupervised learning constitutes a major human development psychology component in children and adolescence learning behaviors. In unsupervised learning, an AI system is presented with unlabeled, uncategorized data, and systemâ€™s algorithms act on data without prior training. The output is dependent upon coded algorithms. Subjecting a system to unsupervised learning is a way of AI testing. Unsupervised learning algorithms can perform more complex processing tasks than supervised learning systems. Yet unsupervised learning can be more unpredictable than the alternate model. An unsupervised learning AI system might, for example, figure out on its own how to sort cats from dogs; it might also add on unforeseen and undesired categories to deal with unusual breeds, creating a clutter instead of an order (Fig. 3.10). 3.8 Reinforcement Learning Reinforcement learning is also known as conditioning (Domjan 2016) in Behavioral Psycholog y . It is a type of learning and training process that will strengthen an organismâ€™s future behavior whenever that behavior is preceded by a specific antecedent stimulus. Laboratory research on reinforcement is usually dated from the work of psychologist Prof. Edward Thorndike (1847â€“ 1949), known for his experiments with cats escaping from Puzzle Boxes in 1929. Psychologist and behaviorist Prof. B. F. Skinner (1904â€“1990) is referred to as the father of Operant Conditioning , and his work is frequently cited in connection with this topic (Skinner 2014). His 1938 book The Behavior of Organisms: An Experimental Analysis (Skinner 2006) initiated his lifelong study of operant conditioning and its application to human and animal behaviors. Following the ideas of physicist Prof. Ernst Mach (1838â€“1916), Skinner rejected Thorndikeâ€™s reference to unobservable mental states such as satisfaction, building his analysis on observable behavior and its equally observable consequences. He believed that classical conditioning was too simplistic for use to describe something complex as the human behavior. Operant conditioning, in his opinion, was more suitable to describe human behavior as it examined intentional behavior causes and effects. He developed a device called the Skinner Box which records each response provided by an animal and its unique reinforcement schedule that was assigned. Pigeons are placed in operant conditioning chambers and receive a food pellet for pecking at a response key. Some pigeons receive a pellet for every response (continuous reinforcement) while others obtain a pellet only after a certain amount of time or numbers of response occurred as in Fig. 3.11. There are two types of reinforcement learning , known as positive reinforcement by rewards and negative reinforcement by punishments . If the object under investigation performs the desirable action or response, a reward is offered, e.g. food, whereas if the object performs unwanted behavior, punishment action is taken, e.g. no food. Tremendous research on reinforcement learning have been done for the past half century, ranging from animal trainings to human learning memory enhancement, which is an important research domain in behavioral and psychological development. The entire Western education exerts reinforcement training for students to awards on good examination grades or fair punishment on poor examination grades to trigger and reinforce learning incentives . The study of reinforcement training and learning had produced an enormous body of reproducible experimental results. Reinforcement in the business world is essential in driving productivity. Employees are constantly motivated by positive stimuli such as promotion and bonus. Employees are also driven by negative reinforcement such as work on off days if weekly workloads are not completed on time. Even today, reinforcement training and learning is a central concept and procedure in special education such as applied behavior analysis. The experimental behavior analysis is also a core concept in certain medical and psychopharmacology models such as addiction, dependence, and compulsion, and of course; a major research topic in AI and machine learning (Fig. 3.12). 3.9 Biological Neural Networks 3.9.1 Our Brain How can we Learn and Think?â€”our brain. Artificial Neural Networks (Aggarwal 2018), ANN (or Neural Networks in short), is a microscopic AI major component that focuses on studying and modeling of an intelligent system to mimic one of the most important human organsâ€”our brain. The first scientist to work on brain science area was biologist and pathologist Prof. Camillo Golgi (1843â€“1926) who invented the staining method to investigate neural activities inside the brain. By using this method, he proposed that the brain is made up of syncytiumâ€”a sponge-like tissue that is activated by the staining operation. Based on his discovery, neuroanatomist Prof. Santiago RamÃ³n y Cajal (1852â€“1934) proposed an innovative idea that â€œthese staining tissues were not sponge-like elements, but rather the collections of brain cells called neurons â€, which were interlinked together to form a complex  groupâ€”neural networks (Mazzarello 2010). Figure 3.13a, b shows 3D modeling and graphical illustration of biological neural networks in our brain. As shown, each neural cell (neuron) consists of Nucleusâ€”central body of the neuron. Axonâ€”prolonged filament connections to other neurons. Dendritesâ€”tree-like structures branching from the neuron. Synapseâ€”axon tips (junctions) contact with other neurons by attaching to the dendrites of neighboring neurons. 3.9.2 Integrate-and-Fire Operations in Biological Neural Network Before 1943, almost all neuroscientists believed that the sole purpose of neurons was to process energy, but how they work, e.g. process information and store memory, remains unknown. Neurophysiologist and cybernetician Prof. Warren McCulloch (1898â€“ 1969), and logician Prof. Walter Pitts (1923â€“1969) published an influential paper in 1943 A logical calculus of the ideas immanent in nervous activity (McCulloch and Pitts 1943) which triggered the birth of artificial neural networks (ANN). They proposed that the main function of neural activities was to process information, not energy storage. The function of neurons was like logical switches . The signal transmission from one neuron to another at synapses is the result of a complex chemical process in which specific transmitter substances are released from junctions sending points. If the potential reaches a certain threshold, a pulse will be generated down the axon known as firing as in Fig. 3.14. More importantly, they demonstrated how their proposed network (now called artificial neural network ) could be used to perform basic logical operations such as AND, OR, and NOT . This breakthrough not only solved the centuryâ€™s mystery of how biological neural network works, but also provided a solid foundation for digital computing technology development. Although we now know that the neural activities in our brains are quite different from logical switches such as transistors in a digital computer, which are alike for nonlinear, and even chaotic integrate-and-fire operators for information transmission and processing, the discovery in 1943 coined the so-called First Golden Age of Artificial Neural Networks. 3.10 Artificial Neural Networks 3.10.1 A Neuron Model As a direct analog of a biological neuron, the schematic diagram of neuron structure can be interpreted as a computational model in which synapses are represented by weights that modulate the effect of associated input signals, with the formulation given by (Fausett 1993; Aggarwal 2018): (cid:2) n(cid:3) (cid:4) y = f wi x i i =1 (3.1) where x is the input signals, wâ€™s are the weights and y is the output. The nonlinear characteristics exhibited by the neuron are represented by a transfer function f (x ) such as a binary or bipolar sigmoid function, given by Binary sigmoid function: Bipolar sigmoid function: f (x ) = 1 1 + eâˆ’Ïƒ x f (x ) = 1 âˆ’ e 1 + eâˆ’Ïƒ x âˆ’Ïƒ x (3.2) (3.3) where Ïƒ is the steepness parameter to control the curvature of the transfer function. Figure 3.15a, b illustrates the contracts between a biological neuron in our brain and an artificial neural network neuron model. The learning capability of an artificial neuron is achieved by adjusting the weights in accordance with a predefined learning algorithm, usually in the form of  w j = Î±Ïƒ x j (3.4) where Î± is the learning rate and Ïƒ is the learning momentum. 3.10.2 Artificial Neural Network Typical artificial neural network (ANN) consists of intermediate layer(s) known as hidden layers to facilitate nonlinear network system computational capabilities (Fausett 1993; Aggarwal 2018). Classical ANNs such as the Feedforward Neural Network (FFNN) illustrated in Fig. 3.16 allow signals (information) to flow from input units to output units in a forward direction. As shown, a typical artificial neural network had a 3-layering structure that consists of (1) input layer with neurons x i ; (2) hidden layer with neurons y j ; and (3) output layer with neurons z k . The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from input nodes through hidden nodes (if any) and to output nodes. Other basic ANNs include the classical Kohonen self-organizing map (SOM) and Learning Vector Quantization (LVQ) based on competition, and the Adaptive Resonance Theory (ART), and of course, our main themeâ€”Feedforward Backpropagation Neural Network (FFBPN). ANNs can be regarded as multivariate nonlinear analytical tools known to be superior at recognizing patterns from noisy, complex data, and estimating their nonlinear relationships. Many studies revealed that ANNs had the distinguished capability to learn the underlying mechanics of time-series problems ranging from stock prediction and foreign exchange rates in various financial markets to weather forecasts. 3.10.3 Classification of Neural Networks by Machine Learning Technique There were numerous neural networks proposed throughout the past half century with over 20 different artificial neural network (ANN) types commonly used (Lee 2006). ANNs are commonly classified by (1) Machine learning technique and (2) Areas of application. In terms of machine learning techniques, ANNs can be classified into three main categories as shown in Fig. 3.17: (1) Supervised Learning Neural Networks Network learning (training) based on inputâ€“output (target output) pairs. Typical examples include Feedforward Backpropagation Neural Network (FFBPN), Hopfield Network , Support Vector Machine (SVM), Radial-basis Function Network (RBFN), etc. (2) Unsupervised Learning Neural Networks Neural networks that do not require any supervised learning and training strategies that include all kinds of self-organizing, self-clustering, and learning networks such as SOM and ART (Adaptive Resonant Theory). (3) Reinforcement-Learning Neural Networks Different from supervised learning (SL) with well-defined inputâ€“output pairs, reinforcement-learning (RL) trains neural networks with the adoption of feedback signals namely reinforcement signal (RS). With the right behavior, the network will respond with a positive RS to award the RL network, while toward the wrong behavior, the network will respond with a negative RS to punish the RL network. This method is particularly useful to tackle the optimization problem without exact target solutions such as trading strategy optimization. 3.11 Machine Learning Models 3.11.1 Associative Neural Network for Associative Learning Associative learning (Findler 2016) is one of the most fundamental human intellectual behaviors to recall and handle memory storage revealed in Sect. 3.4. It is widely used by humans and machines for pattern recognition such as visual pattern identification and recognition for recalling human faces, voices, and music. It relates to knowledge and memory recalling association. In general, an associative neural network (also known as associative memory network or memory network in short) is a single-layered neural network used to store a set of patterns (memory) for pattern association (or what we call memory recalling ). Figure 3.18 illustrates a typical associative neural network configuration. Associative network training is conducted by iterative stored patterns presentation for weights updated according to the training algorithm. Once the training is completed, the network can be used to associate not only stored pattern, but also the correct stored pattern upon an incomplete or noisy query pattern presentation. There are basically two major kinds of associative networks: (1) Auto-associative networksâ€”in which input (and query) patterns are the same type (and nature) as an associated pattern; and (2) Hetero-associative networksâ€”in which input (and query) patterns are completely different types (and nature) from associated patterns. 3.11.2 Hopfield Network for Memory Storage and Retrieval In 1984, physicist and scientist Emeritus Prof. John Hopfield published his influential paper: Neurons with graded response have collective computational properties like those of two-state neurons (Hopfield 1984). He described how a simple recurrent auto-associative network can be used for content-addressable memory systems. This network can also be used for pattern recognition and tackle complex optimization problems such as the typical traveling salesman problem (TSP) (Applegate et al. 2007, Li et al. 2016). The architecture of the Hopfield network is alike as a classical autoassociative network but with three basic differences: (1) The Hopfield network is a recurrent network where output nodes are fed in one time-step as input in the next time-step. (2) In classical associative network, all neurons will update their activations simultaneously, but in the Hopfield network only one neuron will be chosen to update its activation at a time and will then broadcast its new state to other members of the network. (3) Each neuron will keep on receiving the stimulus from an external signal during the entire process. Figure 3.19 illustrates the original system architecture of the discrete Hopfield network (Lee 2006). One of the important points from the Hopfield network is that it demonstrates how a simple auto-associative network can be modified to produce a powerful memory storage and retrieval device. In fact, the vast application areas of Hopfield networks also triggered the rebirth of ANNs, and the exploration of how neural networks can be applied to complex problems in daily operations. Hopfield networks also provided a model for understanding human memory and important AI components (Lee 2006; Yang et al. 2017). 3.11.3 Feedforward Backpropagation Network for Supervised Learning FFBPN provides a multilayer network architecture and is different from the previous two neural networks. A typical FFBPN consists of an input layer, a hidden layer, and an output layer. Although FFBPN can consist of several hidden layers, in most of the cases one hidden layer is usually sufficient (Fausett 1993; Aggarwal 2018). FFBPNâ€™s network training consists of three main processes: (1) The feedforward process of network training. (2) The error evaluation process to calculate errors between calculated output values and target output values. (3) The backpropagation errors process for weight adjustments. Figure 3.20 illustrates the system architecture of a typical FFBPN. In the network architecture, wâ€™s denote the network weights between input and hidden layers, and uâ€™s denote the network weights between hidden and output layers. The total number of neurons in input, hidden, and output layers are n, t, and m, respectively. For the activation functions, a sigmoid function is adopted normally. FFBPN is alike as most other neural networks, training stops when errors are bound within the tolerance level. As shown in the network training process, it learns by comparing network outputs with target outputs and adjusts the network weights between output layer/hidden layers and hidden layer/input layer in the backward mention. So FFBPN is particularly useful for Supervised Learning problems which have well-defined input/targetoutputs for network training. An FFBPN can model various kinds of pattern recognition problems such as character recognition, classification, and optimization. It can also be used at time-series prediction problems such as weather prediction and stock forecasting (Lee 2006). 3.11.4 Actor-Critic Multi-agent Model for Reinforcement Learning There are many situations in which input/target-output pairs do not exist which are different from the supervised learning model with well-defined â€œinput/target-output â€ pairs to traiin the network. Reinforcement learning (RL) is an area of machine learning concerned with how an AI system called intelligent agents (Lee and Loia 2007) ought to take actions in an environment in order to maximize the rewards (positive rewards) and minimize the punishments (negative rewards) alike to humans and other animals learnt from reinforcement training and conditioning. RL does not need any input/output pairs for training. Instead, the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) via reward and punishment mechanisms while the agent life cycle interacts with the environment. One of the most frequently used intelligent agent-based reinforcement learning systems is the Actor-Critic Reinforcement Learning system (ACRLS) as shown in Fig. 3.21. A typical ACRLS consists of four components: Environment Space (E), Action Space (A), Actor Agent (Actor), and Critic Agent (Critic). ACRLS visualizes its world as a collection of discrete-time-step states and actions. The role of the Actor agent is based on input signals provided at the current state at time t to respond with the best available actions (a), whereas the role of the Critic agent is to evaluate the reward signal (r) based on action(s) taken by the Actor and signals provided by new states at time t. Then the reward signal gives feedbacks as input to the Actor agent to decide the next action a at time t + 1. RL is particularly useful to problems that involve a long-term versus short-term reward trade-off. Today, intelligent agent-based RL systems are frequently used in robot control and navigation, elevator scheduling, and telecommunications. It is also commonly found in AI-based board games such as backgammon, checkers, and GO (Wiering and Otterlo 2012; Sutton and Barto 2018). 3.12 Case Studyâ€”Learning at School The best place to study learning methods initially, of course, is by learning at school. The 3 types of learning methods supervised learning, unsupervised learning, and reinforcement learning are always integrated and mixed with our daily learning activities that range from learning concepts and ideas from lectures, for tests, self-revision, and examinations. The learning activities include Attending lectures; Participating in tutorials and labs; Reading books and papers; Completing assignments and exercises; Participating in group discussions; Completing term tests and quizzes; Study and revision; Attending the final exam. Please identify the learning method(s) involved in each learning activity. Discuss how and why schooling consists of all kinds of learning activities (Fig. 3.22). 3.13 Conclusion In this chapter, we explore the first and foremost AI component and technologyâ€”machine learning (ML). Since ML is a core AI characteristic, without it, the system is hardly an AI system. We discover how humans learn. There are three major learning model components: supervised, unsupervised, and reinforcement learning. Although these three learning models are independent of each other, we normally use and combine them unconsciously for our daily learning and training operations. We also studied how our brain works in order to think and learnâ€”biological neural networks in our brain that lead to the design of artificial neural networks (ANN)â€”the mathematical and computational counterparts of the human brain to simulate human memory, learning, and thinking processes. To illustrate different types and models of memory storage, thinking and learning operations, we introduce four basic types of ANNs: Auto-associative network for associative learning; Hopfield network for memory storage and retrieval; Feedforward backpropagation neural network for supervised learning; Actor-critic multi-agent-based model for reinforcement learning. As one might see, all types of AI machine learning techniques are inspired by our knowledge and understanding of human thinking, learning processes, and memory storage which are the soul of AI. 

Data is the fabric of the modern world: just like we walk down pavements, so we trace routes through data, and build knowledge and products out of it. Prof. Ben Goldacre (Physician, born 1974) Abstract This chapter explores various methods and technologies that involve data mining that includes KNN for clustering, decision tree for decision-making, regression for forecast and projection, and association rule for mining useful patterns. We also introduce deep neural networks (DNN) in data mining. The truth is there are many other useful data mining tools and technologies; the focus of the chapter is to provide readers an overview of concepts and key technologies, and more importantly, on how it can be applied to our real-world daily activities. A practical solution should involve data mining and knowledge discovery from different data sources, data formats, and appearances. In Chap. 3, we learnt different types of machine learning methods and technologies ranging from pattern recognition, memory storage to forecasting to solve various real-world problems. Is there any alternative to see the problem? The answer is a definitely yesâ€”Data Mining . We refer to Kantâ€™s remarkable work Critiques of Pure Reason and interpreted it in layman terms: What we perceive in our world depends on the way we see the world. The way we see our world will affect the way we solve the problem happening in our perceived world . In other words, if we consider a problem as a machine learning problem, what we can do (and will do) is to apply appropriate machine learning techniques to solve it. The question is: Is that always the case? Certainly not. However, most of the real-world problems involve data and information. We believe by analyzing and exploring data, we may be able to extract some useful information or even knowledge for a solution. That is the spirit of data mining . In this chapter, we will study different classical (non-AI) data mining methods and technologies, together with the latest AI-based data mining technology and how to apply it to our daily activities. 4.1 What is Data Mining? Data mining (DM) (Tan et al. 2018) is the process of discovering patterns in large datasets involving methods at the intersection of machine learning, statistics, and database systems. DM is an interdisciplinary subfield of computer science and statistics with an overall goal to extract information (with intelligent methods) from a dataset and transform the information into a comprehensible structure for use. Data mining is an important part of the knowledge discovery process that we can analyze on an enormous set of data and obtain hidden useful knowledge. It is also the analysis step of the Knowledge Discovery in Databases process, or KDD in short. DM is useful in commercial sectors such as financial market analysis and financial prediction, weather forecasting, medicine, transportation, health care, and insurance. Figure 4.1 shows the famous data to wisdom hierarchy that can be found in many IT or data science-related books to conceptualize how humans obtain wisdom (intelligence) from raw data we encounter. The entire process of extracting data into information, information into knowledge , and knowledge into wisdom is identical to data mining tasks and objectives. In other words, DM is the process and technology to extract (so-called data-mine ) useful knowledge and even intelligence from all possible raw data of different data sources, media, and domains. 4.2 Why Data Mining Becomes so Important? Data mining has practical applications for a range of common business problems. Organizations become efficient to complete tasks by using various data mining techniques. One example could be preprocessing a set of data that requires human intervention at a later stage. Tasks that required lots of user input before can now be automated to some degree. The saved resources can be used for other means. Beyond task automation, data mining can also be used to analyze large quantities of complex data on predictions as data analysis is an essential task for many businesses. For example, companies analyze sales data to identify profit-making or money-losing segments. Besides, data mining can allow real-time analysis for complex data and be applied to mission-critical systems potentially. It is an explanatory research and development topic in various disciplines ranging from modern medication to space exploration. Currently, machine learning has a lot of limitations and is far from replacing human requirements. However, the constant evolution of data mining technology can offer solutions to difficult problems that take up too many resources ever considered (Fig. 4.2). 4.3 Knowledge Discovery Process (KDP) Knowledge Discovery in Databases (KDD) is the process of discovering useful knowledge from data collection, developed by data scientist Dr. Gregory Piatetsky-Shapiro in 1989. This widely used data mining technique is a process that includes data preparation and selection, data cleansing, incorporating prior knowledge on datasets, and interpreting accurate solutions from the observed results. KDD includes the tools and theories to help us extract useful and previously unknown information (i.e. knowledge) from large collections of digitized data (Piatetsky-Shapiro and Frawley 1991). As shown in Fig. 4.3, a complete KDD process consists of. 1. Selectionâ€”data selection (e.g. from database); 2. Preprocessing â€”data cleansing and preprocessing; 3. Transformationâ€”data transformation to better data mining representation; 4. Data mining â€”data mining of useful information from data (or database); 5. Interpretation and evaluationâ€”data evaluation and presentation into higher level knowledge and information for decision-making.KDD consists of several steps and data mining is one of them. Traditionally, data mining and knowledge discovery were performed manually. As time progressed, data amount grew to larger than terabyte size in many systems that could no longer be maintained manually. Moreover, discovering underlying patterns in data is essential for the successful existence of any business. As a result, several software tools were developed to discover hidden data and make assumptions which formed a part of AI. The KDD process reached its peak in the past 10 years. It now houses many different approaches to discovery that includes inductive learning, Bayesian statistics, semantic query optimization, knowledge acquisition for expert systems, and information theory with its ultimate objective to extract high-level knowledge from low-level data. 4.4 Data Preprocessing Why does data need preprocessing? Data preprocessing (GarcÃ­a et al. 2014) is a data mining technique that involves transforming raw data into an understandable format and is a proven method of resolving problems. We acquire thousands or millions of data (data transactions) from different sources and channels in the real world every day, e.g. sales transactions from a supermarket, patientsâ€™ information from a hospital, and loan information from a bank. These data are often incomplete, inconsistent, and/or lack certain behaviors/trends, and are likely to contain many errors. If we take a closer look at the massive data quality, there are multidimensional views that we need to consider: â€¢ Accuracyâ€”data (data transaction) is accurate or not. â€¢ Completenessâ€”data is complete or not. â€¢ Consistencyâ€”data itself is consistent with other related data (information). â€¢ Timelinessâ€”data is timely updated. It is particularly important for some time-sensitive data mining problems such as weather or financial predicâ€¢ Believabilityâ€”is data credible? tions. â€¢ Interpretabilityâ€”is data easy to understand? Basic data preprocessing includes â€¢ Data cleaning, â€¢ Data integration, â€¢ Data transformation, and â€¢ Data reduction (Fig. 4.4). There is a large amount of muddy and incorrect data in the real world, e.g. faulty instrument, human or computer error, and transmission error. Data cleaning , also known as Data Cleansing (Ilyas and Chu 2019), aims at handling basic problems appearing in the data (raw data) which includes â€¢ Incomplete data : interest, or contain only aggregate data, e.g. Occupation = â€œâ€ (missing lack of attribute values, lack of certain attributes of  â€¢ Noisy data : contain noise, errors, or outliers, e.g. Salary = â€œâˆ’10â€ (an error); data); â€¢ Inconsistent data : contain discrepancies in codes or names, e.g. Age =  â€œ42â€, Birthday =  â€œ03/07/2010â€ was rating â€œ1, 2, 3â€, now rating â€œA, B, Câ€ which is a discrepancy between duplicate records (Fig. 4.5). How to Handle Missing D. Data? â€¢ Ignore the tuples: appear when a class label is missing usually (when doing classification)â€”not effective when % of missing values per attribute varies considerably â€¢ Fill in the missing value manually: tedious + infeasible? â€¢ Fill it in automatically with: a global constant: e.g. using the attribute mean for all samples belonging to the same class or using the most probable value generated from inference-based engines such as Bayesian formula or decision tree. How to Handle Missing Data? â€¢ Binning â€”First, sort data and partition it into (equal-frequency) bins, then smoothen by the means, median, boundaries, etc.; â€¢ Regressionâ€”Smoothen by fitting data into regression functions; â€¢ Clustering â€”Detect and remove outliers; â€¢ Semi-supervised methodsâ€”Combine computer and human inspection. Detect suspicious values and check by human (e.g. deal with possible outliers). How to Handle Data Inconsistency? â€¢ Detect data discrepancy: Use metadata (e.g. domain, range, dependency, â€¢ Check field overload; and distribution); â€¢ Check uniqueness rule, consecutive rule, and null rule; â€¢ Use commercial tools to perform data scrubbing; â€¢ Use simple domain knowledge (e.g. postal code and spell-check) to detect â€¢ Audit data by data analysis to discover rules, relationship and detect errors and make corrections; violators (e.g. correlation and clustering to find outliers). 4.6 Data Integration Data integration (Doan et al. 2012) involves combining data from multiple sources into a coherent store for data mining. Data integration allows different data types (i.e. data transactions inside the database, document, and tables) to be merged by users, organizations, and applications to use for personal or business processes and/or functions (Fig. 4.6). Why Do We Need Data Integration? â€¢ Data is inconsistent and redundant across different data sources (databases), e.g. same person has different name formats across different â€¢ Data is dispersed into different formats and data sources (e.g. texts, audios, databases. videos, figures and graphical formats, or even human dialogues and musical notes). â€¢ Data is dispersed across different databases, OS platforms, and locations (PC server, mobile, cloud, etc.) Common Methods of Data Integration â€¢ Data consolidation is to combine data together from several separate systems physically and create a consolidated data version into one data store. The goal of data consolidation is to reduce the number of data â€¢ Data propagation is the use of applications to copy data from one location storage locations. to another. It is event-driven and can be done synchronously or asynchronously. Most synchronous data propagation supports a two-way data â€¢ Data virtualization is to use an interface to provide a near real-time, unified exchange between the source and the target. data view from disparate sources with different data models. Data can be viewed in one location, but not stored in that single location. Data virtualization retrieves and interprets data, does not require uniform formatting â€¢ Data federation is technically a form of data virtualization. It uses a virtual or a single point of access. database and creates a common data model for heterogeneous data from different systems. Data is brought together and viewed on a single point of â€¢ Data warehousing is the use of data warehouses that are storage repositories access. for data. It also involves data cleansing, reformatting, and storage which is basically data integration. Advantages of Data Integration â€¢ Consolidates data into a more informative format; â€¢ Improves the ease of data/information access and data mining in terms of â€¢ Reduces access time on different databases and resources during the data efficiency and accuracy; â€¢ Resolves inconsistent and redundant data during data mining; mining process; â€¢ Transforms and unifies data into easier access data mining conditions; â€¢ Improves data visualization, user views, and experiences; â€¢ Prepares big data for data mining and data analytical processes. 4.7 Data Transformation How do we see data to understand the information? Let us have a look at the financial market and we will see how important data transformation is. In short, Data transformation (Tan et al. 2018) is the process of changing the format, structure, or values of the data from one form to another in order to (1) make it more easy to understand (for both human and machine) and extract useful information and knowledge; (2) get rid of unrelated and incorrect information and focus on vital and useful information; and (3) transform data that appeared to be completely random or unrelated into useful information and knowledge that can be extracted using data mining technique(s) in high-level perspective. Figure 4.7a, b shows two presentations of financial data such as Dow Jones Indices (DJI) in raw data format and graphical format (financial chart). The truth is, from a financial expert perspective, once financial data is transformed into a financial chart, they can identify many critical financial patterns (such as Head-and-Shoulder pattern ) and trends based on the so-called technical analysis and chart analysis techniques (Murphy 1999; Bulkowski 2007). Major data transformation methods include â€¢ Smoothingâ€”focus to remove noise from data. Techniques include data â€¢ Aggregationâ€”focus to summarize data operations, e.g. the daily transacfiltering, binning, regression, and clustering. tions of a supermarket summarized into weekly and monthly sales to refiect â€¢ Discretization. the big picture of sales performance. â€¢ Normalization. â€¢ Feature extraction. Data Discretization Data discretization (Wohlmuth 2001) is the process of transferring continuous functions, models, variables, and equations into discrete counterparts. This process is usually carried out as an initial step toward making them suitable for numerical evaluation and implementation on digital computers. In terms of data preprocessing, a good data discretization method can not only decrease raw data amount to process data mining effectively, but can also reorder (reformat) raw data so that it can refiect more important information and features for data mining. Basic data discretization methods include. (1) Categorization technique This technique can be used if the source data can be grouped and categorized into some meaningful classes and categories. For example, the raw data of age groups are usually discretized into interval labels: 9â€“ 12 children; 12â€“19 Youth; 19â€“30 Young Adults; 30â€“45 Adults; 45â€“65 Middle Age; >65 Aged as in Fig. 4.8a. (2) Binning technique Data binning, also known as data bucketing, is a data preprocessing method used to minimize the effects of small observation errors. The original data values are divided into small intervals known as bins (or buckets) and then they are replaced by a general value calculated for that specific bin. For example, for the ease of organizing data of a group of products sold in a store, all products are discretized into 11 bins with prices ranging from less than 60 to over 105 as shown in Fig. 4.8b. By using such discretization method, data in each bin contain sufficient data amount for the data mining process. 4 Data Mining 83 Also, the labels used in the discretization method can be organized into higher level concepts, resulting in a concept hierarchy for the numeric attribute. A good discretization method can not only simplify the source data volume, more importantly, it can reorganize raw data to minimize bias by data (data bins) with very few frequencies so that data mining can focus the mining on more representative data (data bins). 4.9 Data Normalization Data normalization is the process of organizing data (say within a database) to reduce redundancy and improve data integrity. In terms of data transformation, data normalization (Blokdyk 2020) has an additional meaning to transform raw data so that data of different attributes provide an equal weighting and will not be biased by actual data quality. Letâ€™s use a realistic case to demonstrate how it works. We studied Artificial Neural Networks (ANN) (Fausett 1993) which can be used for different AI applications, including weather forecasting. Figure 4.9 illustrates a 7-day weather forecast realistic case using ANN (Taylor and Buizza 2002). ANN required historical time-series weather elements as input that include Air temperature (Temp), Mean-sea-level-pressure (MSLP), Relative humidity (RH), Wind direction (WD), and Wind Speed (WS). As one can see, the number range of different weather elements is completely different. For example, Air Temperature (T) normally ranged between 5 and 35 (Â°C), Mean-sea-level-pressure is around 9000â€“12000 (P), and Relative humidity is ranged around 30â€“98 (%). If we simply feed in all these raw data into ANN, the element with higher quality will usually bias the ANN and result in poor forecasting performance. This is where normalization comes to the picture. Instead of using the actual quality of input data, we normalize all these input elements into numbers ranged between 0 and 1 (or between âˆ’ 1 and +1) so that all input elements will be equally ranged and weighted in the network training and forecast. Common data normalization methods include â€¢ Minâ€“max normalizationâ€”the most frequent and simple method used by exercising linear normalization between maximum and minimum values of â€¢ Z-score normalizationâ€”this method is commonly used if data distribution the data range. falls into a typical normal distribution. In this case, data normalization is â€¢ Normalization by nonlinear scalingâ€”the first two methods are functional evaluated by using the mean (Î¼) and standard deviation (Ïƒ) of the data. when data elements are either evenly or normally distributed. But, how about the data that are nonlinearly distributed? In this case, we can exercise a nonlinear scaling function such as an exponential function to transform the data from [âˆ’âˆž, +âˆž] to [0, 1]. 4.10 Feature Extraction Before we study what is Feature Extraction (Liu and Motoda 1998), letâ€™s begin with a daily scenario on human face identification. Some of us may have bumped into someone in the street who looked familiar to a person we knew. Because of the wrong identification, we apologized with probably an explanation to the person involved who resembled our friendâ€™s facial features. We all learnt that human faces consist of important landmarks and features such as eyes, ears, nose, lips, and cheekbone shape. Throughout human evolution, we have been trained and are capable to extract important facial landmarks and features subconsciously to identify human faces. By adopting this concept, feature extraction aims at the extraction of important features from raw data, particularly useful for complex data such as image patterns. Common feature extraction methods include (1) Landmark feature extraction method (Lee 2003)â€”used for data that is able to identify significant and distinct landmarks. They are commonly found in visual patterns and image processing problems such as fingerprints and human face as in Fig. 4.10a, b to show distinct fingerprints and human face landmarks for feature extraction. Feature extraction methods include wavelet extraction and Principal Component Analysis (PCA). (2) Feature filtering method (Liu and Motoda 1998)â€”used for data that is unable to identify significant and distinct landmarks. In this case, some filtering algorithms would be applied to filter noisy data or extract significant data from the overall data source. These methods are useful on various data sources including image patterns, soundtracks and music, and even massive DNA sequences. The frequently used filtering methods include Fast Fourier Transform (FFT) in signal processing, Gabor filter, and Kalman filter . (3) Domain-specific feature extraction and data transformation methods The above two feature extraction methods are generic to any data and problem domains. Domain-specific feature extraction and data transformation methods are tailored for specific data mining problems, e.g. lengthy historical and engineering data such as finance or weather analysis and forecasting (Blum 2019). Here, we use weather forecasting again as an example. Meteorologists transform the surface weather chart into two useful charts: pressure chart of contour line and streamline construction for wind flow instead of data mining weather observation data such as MSLP, temperature, wind speed, and direction shown in Figs. 4.11 and 4.12. In fact, trained meteorologists can identify high-, low-pressure centers and overall current weather situation by simply observing the streamlines and pressure contour charts. Financial analysis is another classic example. Technical analysts already constructed a useful financial time-series data transformation method called technical indicators and oscillators frequently used in all financial markets since the 1970s. Typical financial indicators include Moving Average (MA), Relative Strength Index (RSI), Bollinger Bands (BB), Stochastic oscillators, and MACD indicator . Figure 4.13 shows a DJI market pattern chart with 4 technical indicators: Bollinger Bands, RSI, Stochastics, and MACD. A trained technical analyst can already gain a big picture and trend (bull or bear) of the current market by observing these financial patterns and technical indicators. These financial indicators and oscillators also provide excellent data mining information (Lee 2020). 4.11 Data Reduction What is Data Reduction? A database or data warehouse may store terabytes of data and require a lengthy process to analyze data and mining normally. Data Reduction (Bevington and Robinson 2002) techniques can be applied to obtain a reduced dataset representation in a compact volume but contain all critical information. Common Data Reduction Methods : (1) Data compressionâ€”It is the process to reduce the data size by using different encoding mechanisms. It can be divided into two types based on the compression techniquesâ€”lossy versus lossless data compression. The main difference between the two compression techniques is that the lossy compression technique cannot restore the data from its original form after decompression, whereas lossless compression can allow data to be restored and rebuilt from its original form after decompression. Typical examples can be found in sound, image, and video compression. Discrete Wavelet Transform (DWT) technique and Principal Component Analysis (PCA) are examples of these compression methods. A good example of lossy image data compression is the JPEG image format. A common lossy image compression format reduced the image size effectively but preserved all important features from the original image. Figure 4.14 shows a typical example of lossless versus lossy compression of the same landscape image. It is in fact difficult to identify the difference from a lossy image compression format such as JPEG unless we enlarge the image a great deal to compare with the original or lossless image. (2) Linear and nonlinear regressionâ€”Regression method is a classical statistical method for the generalization of a set of data and observations using either linear or nonlinear functions (or lines in 2D space). Figure 4.15 shows how a set of data (observations) can be represented by a straight line using the linear regression technique. In terms of data reduction, using the regression line to represent the dataset can reduce data size and data mining speed effectively rather than using all observations for data mining. Regression techniques are also frequently used as a data mining tool and method at simple data mining problems. (3) Histograms and clustering techniquesâ€”As mentioned in the previous section, histogram provides an easy to use and effective solution for Data Discretization. It also provides an excellent task on Data Reduction. For instance, to analyze Daily Returns (r) of Dow Jones Index (DJI) for the past 2000 trading days, we consolidate these 2000 daysâ€™ data into 100 intervals between 0.975 and 1.023 as shown in Fig. 4.16. By analyzing and data mining these 100 return intervals, the data size is effectively reduced but the preserved information is contained in the data sources. Also, further data reduction can also be done for this histogram by plotting the nonlinear regression curve over the histogram, shown as a blue regression curve in the figure. In other words, different data reduction methods can be combined to perform preferable data reduction outcomes. (4) Data cube aggregation techniqueâ€”First of all, what is a Data Cube ? A data cube is a type of multidimensional matrix that allows users explore and analyze a data collection from many different perspectives, usually consisting of three factors (dimensions) at a time. For instance, there are over 1000 workers and staff in a toy factory. We are assigned to conduct an overall evaluation. How can we do it? We might think to evaluate staff in 3 aspects: Demographic Data , Organizational Process Data, and Predictive Attitudinal Data and use the data cube method for representation as shown in Fig. 4.17. Thus, by using this 3D data cube, the data can be aggregated so that resulting data summarize the evaluation results from different perspectives and interests. Also, the resulting dataset is compact in volume and without loss of information necessary for data analysis. There are often impeding factors to extract data mining sequel in many data mining problems. These factors are intrinsically variables called features . The higher the feature number, the harder it gets to visualize and work on the training set. Most of these features are generally correlated and hence redundant. This is where dimensionality reduction algorithms come into the picture. Dimensionality reduction (Sun et al. 2016) is the process of reducing the random number variables under consideration, by obtaining a set of principal variables. It can be divided into feature selection and feature extraction. The frequently used dimension reduction methods include wavelet transforms and principal components analysis (PCA) which transform or reduce the original data into a compact space. Attribute subset selection is a method of dimensionality reduction to detect and remove irrelevant, weakly relevant, or redundant attributes or dimensions. A typical example of dimensionality reduction can be found in a simple e-mail classification problem where we need to classify whether the e-mail is spam or not. This involved large numbers of features such as e-mail having a generic title, its contents, and its template. However, some of these features may overlap. A 3D classification problem can be difficult to visualize, whereas a 2D one can be mapped to a simple 2-dimensional space, and a 1D problem to a simple line. Figure 4.18 illustrates this concept where a 3D feature space is split into two 1D feature spaces and later, if found to be correlated, the number of features can be further reduced. 4.13 Classical Methods of Data Mining There are many methods used for Data Mining (Tan et al. 2018) but the crucial step is to select the appropriate method according to the business or the problem statement. Figure 4.19 illustrates the basic data mining methods with four major tasks: â€¢ Classification, â€¢ Clustering, â€¢ Regression, and â€¢ Association. Classification takes present information and merges it into defined groupings. Decision tree method is a frequently used method. Clustering removes the defined groupings and allows data to classify itself with similar items. K-means method is a frequently used method. Regression focuses on the function of information, modeling the data on the concept. Linear regression method is a frequently used method. The final data mining method, association, attempts to find relationships between various data feeds. Association Rules method is a frequently used method. These data mining methods help to analyze market trends, predict future courses, make decisions, and increase company revenue accordingly. 4.14 Classification Using Decision Tree What is a Decision Tree? Decision tree (Tan et al. 2018; Rokach 2014) is one of the most powerful and popular tools for classification and prediction. A decision tree is a flowchartlike tree structure, where each node denotes a specific attribute, each branch of the decision tree represents a possible decision, outcome, or reaction. The farthest branches on the tree represent the end results. It is the most frequent data mining method used to clarify and find an answer to a complex problem such as banking, finance, investment, and business. An organization may deploy decision trees as a kind of decision support system. The structured model allows the chart reader to see how and why one choice may lead to the next, with the use of branches to indicate mutually exclusive options. In other words, the structure allows users to take a problem with multiple possible solutions and display those solutions in a simple, easy to understand format and indicate the relationship between different events or decisions. In a decision tree, each end node has an assigned weight, frequency, or probability. Users look at each terminal outcome for weighting and probability assessment. The tree can span its length as needed until it comes to a proper conclusion. How to Construct a Decision Tree? There are many methods to create a decision tree, the most often used method being Frequent Pattern Classification Technique based on database records and attributes in the database for decision tree generation. This method is frequently used in major organizations such as banks, insurance companies, and financial institutions. In this section, we use a realistic case of loan approval from a bank to create a simple data mining and decision support system based on previous loan approval transactions available in the past 1 year. Figure 4.20 shows the loan approval transaction for 30 cases with four attributes: â€“ Age: Young Adult, Middle Age, or Aged; â€“ Employed: Yes or No; â€“ Own house: Yes or No; â€“ Credit rating: Fair, Good, or Excellent. Figure 4.21 shows a 2-level decision tree on Age (level 1) and Employed/Own House/Credit Rating (level 2). The final loan approval decision is obtained by the following equation: (No. of approval/disapproval cases)/(total no. of cases that meets the requirement). By using the 2-level decision tree, we can data-mine a query as follows: Case 1: Young Adult + Employed â†’ Approval rate 3/4= 75% Case 2: Middle Age + Not own house â†’ Approval rate 5/8 = 62.5% Case 3: Aged + Good Credit Rating â†’ Approval rate 4/4 = 100% So, how about a more complex case with 3-level condition? Figure 4.22 shows a 3-level decision tree with attributes Middle Age (level 1), Employed or not (level 2), and Credit Rating (level 3). Case 4: Middle Age + Employed + Fair credit rating â†’ Disapproval rate From this 3-level decision tree, we can support the following queries: 3/3 = 100% Case 5: Middle Age + Employed + Good credit rating â†’ Approval rate 4/5 = 80% Case 6: Middle Age + Employed + Excellent credit rating â†’ Approval rate 3/3 = 100% In this decision tree, we can also drive another important case: Case 7: Middle Age + Not Employed â†’ Disapproval rate 3/3 = 100% which means that the client is middle age, unemployed, the decision is disapproved regardless of credit rating. 4.15 Clustering Using KNN Method What is Clustering? There is another kind of data mining method, apart from decision tree, we use frequently in daily activitiesâ€”Classification and Clustering (Aggarwal and Reddy 2013). Let us begin with our typical daily life cycle on a normal working day: We wake up, go to a coffee shop for breakfast, our first classification and clustering task is to select our favorite bread or muffin. How do we select? First, 4 Data Mining 97 we cluster unconsciously our favorite breakfast food (e.g. muffin) out of other food varieties. Second, we classify consciously different muffinsâ€™ outlook to select the best one. Afterwards, we take a bus or train to work. We then classify consciously buses or train compartments into different classes or clusters to select the least pressing one to climb aboard. When we arrive and enter the office building, we again classify or cluster consciously or even unconsciously different queues and select the shortest one to take the elevator. We apply the same technique at our work throughout the day. For example, no matter what kind of work we do, we would probably deal with a typical problem: What kind of task(s) to begin with? What is the priority of the tasks? Different individuals use different methods but naturally, most of them are related to classification and clustering in terms of urgency, importance, time-dependency, etc. As we can see, each of them is a typical kind of classification or clustering. We classify these tasks frequently according to different attributes and make the best decision simultaneously. Figure 4.23 shows a typical example of original data versus clustered data into 3 classes (groups). K-Nearest Neighbor (KNN) Technique In data mining, one of the most popular and important classification and clustering methods is the K-Nearest Neighbor (KNN) technique. The concept of the KNN technique is simple: an object or instance (o) belongs to one specific class (c). If we try to measure the distance (d) between this object (o) with all objects of different classes and arrange them according to distances, for a KNN classification strategy, we only consider the first K object with the shortest distance and count the number of objects within each class. The class (o) with the maximum number will be the one this object (o) belongs to. Here, we use a realistic example of studentsâ€™ classification/clustering of a university to illustrate how the KNN method works. To simplify the problem, we assume the student population belongs to 3 different faculties/groups Arts, Management, and Science with three different object shapes and colors as shown in Fig. 4.24. To do classification, we must have some attributes for consideration. Here, we use 2 attributes for illustration purpose, Logical Thinking and Artistic Interest so that it can be shown in a 2D figure. There can normally be 3 or more consideration attributes simultaneously in a real-world situation. The classification/clustering problem is: How can we classify and cluster new student A in that population, provided that we have his scores for Logical Thinking and Artistic Interest using the KNN method? Case 1â€”Using KNN for K = 5 : KNN-5 is shown in Fig. 4.25 where the unknown student is marked with letter â€œAâ€. We have 2 methods to perform KNN clustering for our problem with 2 attributes: (1) Use the  revealed algorithm and calculate all distances between A and all student objects in the figure, sort them according to distance and count first 5 student objects with the shortest distance, and identify which faculty has the maximum student numbers; or (2) simply draw a circle with student A as the center that contains exactly 5 students objects, and count which color objects are with the maximum count. As shown, a circle created includes exactly 5 student objects; the number of counts for KNN = 5, the unknown student should belong to the Science faculty. each faculty is Arts (0), Management (2), and Science (3). Therefore, by using Case 2â€”Using KNN for K = 13 : One might ask: Is it always the same result for different K number? The answer is a definite no. Figure 4.26 illustrates the clustering result when KNN = 13. Using the fast circling method, we can see the result: Arts (0), Management (7), and Science (6). By using KNN = 13, the unknown student should belong to the Management faculty. Why? It all depends on data, priori knowledge, and data distribution. In other words, the choice of K number is critical for data mining. It relies on data analyst/data scientistâ€™s experience to perform the data mining task. One might ask: How can we create 3 clusters at the very beginning? It would be a chicken-and-egg problem. If we do not have the initial data, there wouldnâ€™t be any clusters, and without the clusters there wouldnâ€™t be any classification. The truth is, for any classification problem, we must have 2 basic elements: (1) Some basic objects that have predefined classes to begin with and there will be no cluster; (2) Some basic (at least 2) attributes for evaluation and there will be no way to do distance measurement if otherwise. In fact, once we have both (1) and (2), all KNN classification procedures for all unknown objects will be done and will enlarge the clustering class of the population. KNN is a frequently used method in many real-world data mining problems on population classification, e.g. relationship between occupation and education levels, demographic analysis, voting preference distribution and clustering, and even to a new eatery location. 4.16 Regression Method What is Regression? Regression (Matloff 2017) is a useful statistical-based data mining tool to estimate the relationships between a dependent variable (often called the outcome variable ) and one or more independent variable s (features or attributes ). In terms of data mining and knowledge discovery, regression is used across multiple industries for business and marketing planning, financial forecasting, environmental modeling, and trend analysis. 4 Data Mining 101 Classification Versus Regression Regression and classification are both data mining techniques used to solve similar problems, but they are often confused. Although both can be used on prediction analysis, regression is used to predict a numeric or continuous value while classification assigns data into discrete categories. For example, regression would be used to predict a house price based on the location, size, and environmental factors which are continuous values. On the other hand, classification would be applied for users to choose different house types such as apartment, semi-detached, detached house or a bungalow based on price, location, and environmental factors for which 4 different house types are discrete classes and categories. Linear Regression The most basic and simple type of regression is called Linear Regression. Figure 4.27 illustrates a case of linear regression for a set of experimental observations with two variables: the independent variable x (attribute) and the dependent variable (outcome). Linear regression uses the mathematical formula of a straight line (y = mx + b). In plain terms, given a graph with a Yand an X-axis, the relationship between X and Y is a straight line with a few outliers. The logic behind this is that: Given a population of observations, the straight line with a few outliers provides the best fit and relationship estimation between the attribute and outcome of the data mining problem. Figure 4.28 illustrates the linear regression between the Total Bill versus Tip of the bill of a restaurant as a real-world problem. We might assume that, given an increase of Total Bill , there would be an increase in the Tip amount in a linear manner. To visualize this, consider a graph in which the Y-axis tracks the increase of Total Bill , and the X-axis tracks the Tip. As Y value increases, X value would increase at the same rate, making the relationship between them a straight line. This also illustrates how a linear regression line is formed. As shown, for each observation data, the vertical distance between the observation point and the straight line is known as deviation. So, the regression line is formed by finding a straight line such that the sum of deviations from all observation data is the minimum with the method called least square approach. Although the calculation is quite tedious, thanks to the popularity of linear regression and computer technology, linear regression is almost a standard tool embedded in many applications ranging from Excel in MS Office to data mining and statistical tools such as R, Python, and MATLAB. Nearly all real-world regression models involve multiple attributes, and basic linear regression is often phrased in terms of a multiple regression model (or multivariable linear regression ). Nonlinear Regression Nonlinear regression is a form of regression analysis in which data is fit to a sion relates two variables (X and Y) with a straight line (y = mx + b), while model and then expressed as a mathematical function. Simple linear regresnonlinear regression must generate a line (typically a curve) as if every value of Y is a random variable. Figure 4.29 illustrates a typical nonlinear regressive curve. An example of how nonlinear regression can be used is to predict population growth over time. A scatterplot of changing population data over time showed that there seemed to be a relationship between time and population growth, but that is a nonlinear relationship that is required to use a nonlinear regression model. A logistic population growth model provided population estimates for periods that were not measured, and future population growth predictions. Opposite the nonlinear population growth curve is the famous decay curve , with the name coming from the radiative decay of radiative elements such as Uranium 235. Figure 4.30 illustrates a typical nonlinear radiative decay curve. In fact, the decay curve is commonly found in many real-world situations such as the market economy, finance, biology, and telecommunication. Besides population growth and decay curve, another type of nonlinear regression curve commonly found in many data mining problems is logistic curve , also known as sigmoid curve with its distinctive S-shape. In fact, the sigmoid growth curve is believed to be a natural phenomenon commonly found in many natural science, biology, and medical tests such as drug response experiments. Figure 4.31 illustrates nonlinear sigmoid curves of two vaccine (Bupivacaine and Ropivacaine ) dosages versus responses of patientsü™ pain relief scores. As shown, both vaccines demonstrated typical logistic growth with exceptionally low responses until they reached the first threshold dosage, then the responses grew exponentially until they reached the second threshold dosage. After that, even higher dosages were unable to produce any significant improvement. In other words, an effective vaccine can be clearly identified by using a nonlinear regression technique. More importantly, we could also predict the degree of effectiveness with different dosages and select the optimum dosage for patients. 4.17 Association Rule Method What is Association Rule? In many real-world scenarios, we always want to data-mine patterns, either consciously or subconsciously. These patterns can be anything related to two or more attributes, facts, objects, outcomes, or even thoughts in general. For example, we bring an umbrella when the sky is cloudy and windy. It is natural and common sense but it is a typical kind of Association Rule (Tan et al. 2018; Adamo 2012) in the form: X â†’ Y where X is the cause (or condition ) and Y is the effect (or outcome ). In general, X can be a single condition or multiple conditions, and Y can be anything. It can be an action, decisionmaking, event(s) outcome, or even a condition for another association rule. In terms of data mining, we always named condition elements as items, and a be {cloudy, windy} â†’ {bring umbrella}. group of conditions as itemsets. So, in our example, the association rule will In addition to the above simple daily activity example, association rule has more powerful use in countless daily examples. One of them is data mining of customer habits in a supermarket. In this section, we will try to use a simple case of data mining customer purchase transactions to illustrate how association rule pertains to data-mine customer habit. Figure 4.32 shows a transaction list of 5 customers at a supermarket where TID is the Transaction ID . The list of purchase items included Chips (Potato chips), Nuts, Coke, Coffee, Eggs, and Milk . Before we begin, let us establish some basic definitions using the Association Rule method: â€¢ Itemset is the set that contains one or more items, e.g. {Chips}, {Chips, Coke}. â€¢ K-itemset is the itemset that contains k items, e.g. {Chips, Coke, Milk} is â€¢ Support(itemset) (also written as â€œsup(itemset)â€) is the frequency of an a 3-itemset. itemset X in transaction dataset, e.g. sup(Chips) = 3, sup(Nuts) = 3, sup(Coke) = 4, sup(Chips, Coke) = 3,  and sup(Chips, Nuts) = 1. â€¢ Fraction support s{X} is the probability that a transaction contains itemset X, e.g. s{Chips} = 3/5 = 60%, s{Coke} = 4/5 = 80%, s{Chips, Coke} = 3/5 = 60%, s{Chips, Milk} = 1/5 = 20%. In short, the complete Association Rule Mining is a 3-step process: (1) Identifying patterns (itemsets); (2) Generating association rules from frequent patterns; (3) Mining association rules. What is a Frequent Pattern? An itemset (or a pattern ) X is Frequent if the support of X is not less than the minsup threshold Ïƒ. In a typical data mining case, we will set Ïƒ = 50 (i.e. 50/50) at the beginning. So, in our 5-transaction dataset: (1) All frequent 1-itemsets are s{Chips}: 3/5 (60%), s{Nuts}: 3/5 (60%), s{Coke} 4/5 (80%), s{Eggs}: 3/5 (60%) (Note: Milk and Coffee are excluded as their s{Milk} = s{Coffee} = 2/5 = 40% are less than minsup threshold Ïƒ. (2) All frequent 2-itemsets are s{Chips, Coke}: 3/5 (60%) (Note, all other s{} of the 2-itemsets are less than Ïƒ). (3) All frequent 3-itemsets (or above)?â€”None. 4 Data Mining 107 How to Generate Association Rules? To generate association rule, we make sure of the frequent patterns. As mentioned at the beginning of this section, all association rules are in fact causations (cause-and-effect) generated by our previous knowledge or experiences. In terms of dataset data mining, they are simply the â€œifâ€“thenâ€ kind of association between different patterns (or itemsets). For example, {Coke}  â†’ {Chips} means â€œCustomer who buys Coke may likely buy Chipsâ€. So, one  might wonder: How strong is this association rule? dence (c) as a kind of evaluation of an association rule, like this: X â†’ Y(s, c) To answer the question, we define two thresholds: Support (s) and Confiwhere X and Y are patterns (itemsets). Support (s)â€”the probability that a transaction contains X âˆª Y, or the number of the transaction contains both X and Y over the total number of transactions in the dataset as illustrated in Fig. 4.33. For example, s{Coke, Chips} = 3/5 = 60%. Confidence (c)â€”the conditional probability that a transaction X also contains Y. Based on our previous definition of sup{}, c = sup{X U Y}/sup{X} = s{X U Y}/s{X}. In our example, c = sup{Coke, Chips}/sup{Coke} = 3/4 = 75% How to Perform Association Rule Mining? The basic steps are straightforward: (1) Create TWO thresholds: minsup (minimum support) and minconf (minimum confidence). (2) Generate all possible association rules X â†’ Y (s, c) from itemsets and transaction datasets. (3) Extract association rules X â†’ Y (s, c) that meet the minsup and minconf thresholds, such that s â‰¥ minsup and c â‰¥ minconf. In our example, Set minsup = 50% (50/50, default case). All possible Frequent 1-itemset: s{Chips} = 3/5(60%), sup{Nuts} = 3/5(60%)â€ž s{Coke} = 3/5(80%), s{Eggs} = 3/5(60%). All possible Frequent 2-itemset: s{Chips, Coke} = 3/5(60%). Set minconf = 50% (50/50, default case) All possible transaction rules that meet minconf threshold are {Chips} â†’ {Coke} with c = s{Chips U Coke}/s{Chips} = sup{Chips U Coke}/s{Chips} = 3/3 = 100%, so {Chips} â†’ {Coke} (60%, 100%) {Coke} â†’ {Chips} with c = s{Chips U Coke}/s{Coke} = sup{Chips U Coke}/s{Coke} = 3/4 = 75%, so {Coke} â†’ {Chips} (60%, 75%) This simple example corresponds to an interesting but important datamine association rule about customer habit: Customers buying potato chips would most likely buy Coke as well, but NOT the other way round. How Important Association Rule Data Mining Is? In fact, most of the cross-selling strategies in major departmental stores or online stores use various kinds of data mining strategies to data-mine the 4 Data Mining 109 association rules between different items to push for overall sales performance. Imagine in a supermarket or online store, there are thousands or up to millions of transactions per minute. If we can data-mine the top 100 association rules with over 85% confidence level and the performance of selling cross products, how much extra selling proposition can we generate? There is one closing point to indicate that in a real-world situation, we have over millions of items and millions of transactions per day. Then how can we generate all these association rules automatically? The reason is twofold: (1) After the design of association rules materialized long ago, we already have some excellent algorithms to generate association rules such as Apriori algorithm and FP-growth (FP means frequent patterns) algorithm to automate the entire FP mining process; (2) Thanks to the rapid development of data mining technology, we now have powerful and useful tools such as Python and R to perform the association rule mining automatically. All we need is basic concepts of how association rule works, and more importantly, to have a better knowledge of our problem domain. The truth is, even if we have the best data mining tools to establish data-mine association rules, we still need to interpret the rules and determine actions to execute decisions. 4.18 Deep Neural Networks for Data Mining In Chap. 3, we had learnt different types of AI-based machine learning methods and technologies. Can these methods be applied to data mining too? The answer is yes . Artificial neural networks (ANN), especially multilayer neural networks (Aggarwal 2018; Lee 2006), can definitely be used for data mining ranging from different cluster classifications to time-series weather prediction. Figure 4.34 illustrates the neural architecture of a typical multilayer neural network. However, due to the complexity and massive data volume in many real-world data mining problems such as real-time financial predictions of worldwide financial markets which involve the handling of numerous financial data across different financial markets, i.e. forex (foreign exchange), commodities (e.g. gold, silver, crude oil, cotton, and sugar), and financial indices (e.g. DJI, HIS, and FT100), certain enhancements of classical multilayer neural networks are required where deep neural networks (DNN) comes into the picture. A Deep Neural Network (DNN) is an artificial neural network (ANN) with multiple hidden layers between input and output layers. The machine learning performed by DNN is also known as deep learning . In deep learning, the number of hidden layers can even reach up to 100 layers. Current research revealed that DNN produces much better results than normal ML networks (Lee 2020). The main logic behind this is that if a classical neural network contains more hidden layers, technically speaking, it can learn more complex knowledge and accept more massive input data for machine learning and data mining. So, how does it work? Figure 4.35 illustrates the network architecture of DNN constructed by the author for daily worldwide financial market prediction in quantum finance forecast center (QFFC 2020). As shown, the input layer accepts daily time-series worldwide financial data, together with all the related financial indicators and feeds into an 8level bifurcation hidden layer (BHL) for deep learning to forecast the next-day open, high, low, and closing prices . Since Dec 2018, quantum finance forecast center (QFFC) applied DNN to predict the next-day forecast for over 120 worldwide financial markets including 9 major cryptocurrencies, 84 forexes, 19 major commodities, and 17 worldwide financial indices across different countries. Figure 4.36 shows the official site and daily financial forecast on Mar 27, 2020. Besides the financial forecast, DNN can be applied in various complex data mining problems such as (1) Financial fraud detection (Baesens et al. 2016)â€”Deep learning is being applied successfully to financial fraud detection and anti-money laundering. DNN-based anti-money laundering detection system can data-mine relationships and similarities between money transaction flows and detect anomalies or, classify and predict specific patterns. The solution leverages both classification of suspicious transactions, and anomaly transaction flow alert and detection (Fig. 4.37). (2) Customer relationship management (Berry and Linoff 2008)â€”DNN has been used successfully in the market to approximate the value of possible direct marketing actions, defined in terms of RFM variables: Recencyâ€” How recently do customers purchase? Frequencyâ€”How often do they purchase? and Monetary Valueâ€”How much do they spend? (3) The estimated value function was shown to have a natural interpretation as customer lifetime value and be able to data-mine effectively using DNN technology. (4) Drug discovery and toxicolog y (Hoffmann et al. 2013)â€”A large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored the use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products, and drugs. Current research revealed that DNN such as AtomNet can be used effectively on structure-based rational drug design, and more importantly used to predict novel candidate biomolecules for target diseases such as Ebola virus and multiple sclerosis. (5) DNA sequencing and pattern discovery (Shui 2016)â€”DNA sequencing is the process of determining the nucleic acid sequenceâ€”the order of nucleotides in DNA. It includes any method or technology that is used to determine the order of the four bases: adenine (A), guanine (G), cytosine (C), and thymine (T) as shown in Fig. 4.38. The advent of rapid DNA sequencing methods has greatly accelerated biological and medical research and discovery. Recently, DNNs were proved to be able to extract useful features from input patterns from DNA automatically, which shed light on DNA sequence classification improvement. They also provide vital help to discover the association between DNA anomalous patterns and certain critical diseases such as various kinds of cancers. DNN can also be applied to other AI problems such as Computer Vision (CV) and Natural Language Processing (NLP) which will be explored in the following chapters. 4.19 Case Study: Where to Open a New Pizza Shop? Data mining provides a powerful tool for us to classify, cluster, and even examine customersâ€™ habits and sales predictions. In this case study, suppose we are the Data Scientist of a pizza chain store with over 100 pizza shops across the US, and are assigned to provide all the necessary data mining information for management to open a new pizza shop in the US. The objective is to make use of different data mining methods learnt in this chapter such as classification, clustering, decision tree, association rule, and deep neural networks to achieve the following tasks: (1) Where is the best location to open a new shop? (2) What kinds of food to be sold in the new shop? (3) How can we do future 1-year sales projection of the new shop? (4) How can we improve the sales performance of the new shop by determining the cross-products sale relationship sold in chain shops of the past 2 years? For example, to select the location, we might consider classification and clustering of demographics across different states in the USA. Figure 4.39 shows a demographic chart of pizza locations across the US in colors, with an illustration of the TOP 10 states in the US. Hints: We might consider the following data mining tasks to solve the problem: â€¢ How to use classification and clustering methods such as KNN to pinpoint â€¢ How to use decision tree to decide what kinds of food to be sold? the best location? â€¢ How to use association rule construction to data-mine customersâ€™ eating â€¢ How to use a regression technique to perform sales projection? habits? â€¢ How to use the DNN technique to improve sales performance? 4.20 Conclusion In this chapter, we study and explore various data mining methods and technologies. They include KNN for clustering, decision tree for decisionmaking, regression for forecast and projection, and association rule for mining useful patterns. We also review the latest AI technologyâ€”deep neural networks (DNNs). The truth is there are many other useful data mining tools and technologies, such as Support Vector Machine (SVM), Principle Component Analysis (PCA), Bayesian networks , and Genetic Algorithms (GA). In fact, the concepts and scope of data mining are enormous to be a self-contented undergraduate course in many universities. The focus of this chapter is to provide readers an overview of concepts and key technologies, more importantly, on how it can be applied to our real-world daily activities. A practical solution should involve data mining and knowledge discovery from different data sources, data formats, and appearances. It is evident that data mining not only is one of the most competitive topics for R&D in AI and scientific world, but it also plays a pivotal role such that many major corporations such as banks, insurance companies, and government departments nowadays have designated Data Science divisions (departments) with hundreds of Data Scientists to data-mine intensive business knowledge or the so-called Business Intelligence (BI) to improve customer service and business development (Fig. 4.40). 
A lot of the future of search is going to be about pictures instead of keywords. Computer vision technolog y is going to be a big deal. Mr. Ben Silbermann (CEO of Pinterest, born 1982) Abstract How do computers see our world? The emergence of AI in 1950s prompted scientists to build machines imitating human in two aspects: How we think and see? The truth is: Human excel at thinking and learning than the machine (computer). We exercise various thinking and learning techniques to acquire knowledge and intelligence. Human has another unique vision ability over the machine. Any computer scientist will tell us that building a machine (robot) to imitate 100% human vision capability is almost an impossible task. This chapter compares the human visual system with computer vision. By imitating human vision, we introduce 3 computer vision components: (1) Figure-scene segmentation; (2) Object recognition, and (3) 3D & VR modelling. After that, we study various latest computer vision technologies and applications related to daily activities. How do computers see our world? The emergence of AI in 1950s prompted scientists to build machines imitating human in two aspects: How we think and see ? Why? The truth is: Human excel at thinking and learning than the machine (computer). We exercise various thinking and learning techniques to acquire knowledge and intelligence. Human has another uniqueness vision ability over the machine. Any computer scientist will tell us that building a machine (robot) to imitate 100% human vision capability is almost an impossible task. To illustrate how amazing human vision is, try a simple experiment. Just close your eyes for 10 s and open it again, then count how many seconds you need to recognize all things and objects you see inside your room. You will be amazed by how rapid and effortless for a human to recognize objects from a scene, such computer vision process is so-called scene analysis and object recognition which is a major research topic in AI and computer science. In this chapter, we explore Computer Vision (CV)â€”how a machine (computer) sees the world? To understand computer vision, we must start with human vision. Firstly, we will study how human sees the worldâ€”our visual system compares with computer vision. Secondly, by imitating human vision, we will introduce three main CV components: (1) figure-scene segmentation; (2) object recognition, and (3) 3D & VR modelling . Thirdly, we will study active vision on robot vision application with major challenges and technologies. After that, we will explicate how various latest computer vision technologies can be applied in our daily activities. 5.1 What is Computer Vision? Computer vision (CV) (Szeliski 2010; Forsyth and Ponce 2010) is a field of computer science enabling computers to see , identify, and process images just like human vision. It is alike imparting human intelligence and instincts to a computer but is an extremely difficult task enabling computers to recognize images of different objects in reality. Computer vision is linked closely with AI. Its goal is not only to see but also to provide appropriate analysis based on the observation and then perform or act accordingly. A good computer vision system should not only capture an objectâ€™s 2D image it sees from the environment, but it must convert it automatically into a 3D object and be able to track its motion. For example, when we design an auto-driving vision system, the vision system not only needs to see all vehicles around us, but more importantly it has to know how they currently move and predict their future moving speeds and directions in order to navigate our car to avoid any potential collision. It also needs to distinguish all other surrounding objects such as pedestrians, traffic lights, traffic signs, and all possible obstacles to avoid. Remember, these are all not static pictures and objects, but are 3D moving objects in real time. One might see, a good vision-enable car navigation system to include many capabilities such as: figure-ground segmentation; object recognition; motion checking; motion prediction; anti-obstacle; and real-time navigation. For instance, such intelligent vision-enable navigation system must provide inputs to the driver or even stop the car automatically if it meets a sudden obstacle on the road (e.g. a dog suddenly runs out to the driving lane), the system must react instantly. It has a similar human vision to identify an object, process data, decide what to do, and complete a complex task in a split-second. CV â€™s aim is to enable computers to perform the same kind of tasks as per humanâ€™s efficacy (Fig. 5.1). 5.2 How Human See the World? CV aim is to build an intelligent system to imitate the human vision system. The first basic question is: How human see the world? This question seems to be a biological and physiological problem, but the truth is a lot more. Any high school student undertook human biology knew how we see any external object is based on our visual system: We can see any external object because light reflects from the external object, e.g. apple enters the lens of our eyes. Alike typical optical system, these lights focus onto the retina of our eyes and stimulate our light sensing cells (rods and cones). The optical signals will be sent via the optical nerve into the visual cortex in our brain and then we can see the object. Figure 5.2 illustrates the basic mechanism of how we see an object, e.g. apple via our visual system. Is this the whole story of how we see or recognize our world? The answer is no. Actually, this visual system mechanism we all learnt in high school could only tell us how the visual information from an external object captured by our visual system (Remington and Goodwin 2004) and sent to the visual processing centerâ€”the visual cortex in our brain. But it did not tell us many important things such as: How can we (1) separate the object we see from the environment? (2) recognize the object we see? (3) shape and model our visual world?, and (4) navigate in this visual world? The first question is what we called figure-ground segmentation problem. It seems to be simple and instinctive, in fact, it is a complex and sophisticated process that took millions of years on human and animal evolution to perfect such capability. The second question is not only a visual processing problem but is a rather high-level epistemological problemâ€”the problem and theory of knowledge. The truth is: To recognize any object, we must have the knowledge of that object first. In other words, we must have a knowledge base to contain all different objects so that we can recognize that object when you see it. 5.3 Real-World Versus Perceived World The third question is uncanny yet interesting. Have you ever thought about a fundamental phenomenon: Does the world we see daily is the same world others see? The answer seems to be yes , but it is obviously no. A simple argument can answer this question: We all should agree that the world we see is based on our 5 Computer Vision 123 visual system. However, the physiological structure of every human cannot be identical, so obviously, the same object we see cannot be completely the same in terms of color, shape, and all other features. In that case, the world we perceive daily maybe similar, but cannot be the same. It is, in fact, a complex cognitive science or even philosophical problem. In laymanâ€™s term, the world we see is a 3D model built in our conscious mind so-called model world (or perceived world ). It is a model world we construct subconsciously in our mind based on daily experiences and interactions with the real-world via our perceptual system. This information about the real-world comes to us initially through our sensory system: vision (eyes), hearing (ears), smell (nose), taste (mouth), and touch (skin). According to the Greek philosopher Platoâ€™s book The Republic , the story of Allegory of the Cave (Plato 2017), described our perceived world is like a projection of the real-world, similar to 3D adventure games or VR (Virtual Reality ) games we play in cyberworld (Magnor and Sorkine-Hornung 2020), or a world expressed in the remarkable sci-fi movie Matrix in 1990s (Wymann 2002). Once we identified what we see is just the 3D model we built inside our mind, how we navigate and interact with this world is nothing more than playing an interactive VR game! Because of this new understanding, some new age theory such as Simulation Theory proposed that we live in a world of simulation, all perception we have include our sensory system are only electrical signals and information fed by the so-called construct , we all interact within this simulated world and assume it is the reality . No one knows whether it is true. However, it is a good example to understand how human perceive the world, and how surprising close to our perceived world as compared with the one simulated by intelligent computer systems (Fig. 5.3).Once we learnt how human vision works, the next question is how to imitate human vision into computer vision. Let us begin to look at the basic visual sensing differences of human versus computer. In the previous section, we studied how human see objects, so how about computer vision? Thanks to theoretical physicist Prof. Albert Einstein (1879â€“ 1955) for his discovery of photoelectric effect (Einstein and Bruskiewich 2014) in 1905, which awarded him the Nobel Prize in 1921, for his discovery of photoelectric effect instead of General Relativity . His photoelectric experiment as illustrated in Fig. 5.4, showed that light beams shined on a metallic plate trigger electrons emission and received at the other end of the vacuum tube to drive current flow in the electric circuit. This innovative experiment set the cornerstone for light sensor R&D on digital cameras and mobile phones. The core of every digital camera has a solid-state device (called light sensor or image sensor ) based on the photoelectric effect to capture light entering the lens to form image pixels. Figure 5.5 illustrates how CV operates via digital image sensor (Nakamura 2005). As one might see, the basic visual processing mechanism inside a digital camera is alike the interior of our eye, the major difference is that digital camera uses millions of image sensors in the form of massive 2D-array to convert incoming light into electronic signals and 2D images. Although it seems that one is an electronic device and the other is a purely biological organ. The truth is: these two devices convert the incoming light into electrical signals ultimately . The only difference is that in the human visual system, electrical flows are conducted via our visual nerves to the visual cortex inside our brain. 5.5 Main Components of Computer Vision Like human vision, visual sensing of the environmentâ€”or what we called the scene in computer vision perspective is only the beginning of the story. To imitate human vision, CV needs to solve the following problems (Bhuyan 2019; Forsyth and Ponce 2010): 1. Segment object from the environmentâ€”figure-ground segmentation 2. Recognize object from the sceneâ€”object recognition 3. Model and navigate inside the computer worldâ€”3D & VR modelling These three domains of computer vision are also the three main components of the CV. Its R&D is mainly focused on fundamental visual-related problems such as image processing, image transformation, and object recognition in the past 50 years. However, owing to the advance of computer technology, digital image sensing and robotic technology, the scope of CV is extended to a more comprehensive and practical level that is closely related to our daily activities. These examples include: 1. How to use biometric technology such as human face, fingerprint, palmprint or iris for entry control and user authentication? 2. How to recognize terrorists inside the public area such as airport and train station using gait recognition (the way and gesture of walking)? 3. How to design and navigate a drone to deliver parcels from suppliers to customers using both GPS and active vision technology? 4. How to design and navigate cars in next-generation of intelligent city using 5G + visual-based auto-driving and navigation technology? 5.6 Figure-Ground Segmentation 5.6.1 Gestalt Theory of Visual Perception Before we explore how the computer performs figure-ground segmentation, letâ€™s investigate how human achieve that goal. Figure-ground segmentation has a long history of study not in computer science, but in visual perception psycholog y (Hamlyn 2017)â€”a branch of psychology focus on how we percept our world in terms of visual perception to be considered as the original computer vision of psychology. Hence, Gestalt psycholog y (or Gestaltism ) is one of the most influential theories in visual psychology emerged in early twentieth century based on the works by psychologists Profs Max Wertheimer (1880â€“1943), Wolfgang KÃ¶hler (1887â€“1967), and Kurt Koffka (1886â€“1941). Gestalt Psychology explained how to acquire and maintain meaningful perceptions in our world of perception (Kohler 2014; Wertheimer et al. 2012). The central principle of Gestalt psychology is that the mind forms a global whole with self-organizing tendencies. This principle maintains that when the human mind (perceptual system) forms a percept or gestalt , the whole has a reality of its own, independent of the parts. The key principles of gestalt systems are: Emergenceâ€”human mind auto-organize parts to the whole . Reificationâ€”constructive or generative aspect of perception (human mind complete gaps to form meaning). Multi-stabilityâ€”the tendency of ambiguous perceptual experiences to pop Invarianceâ€”the property of perception whereby simple geometrical back and forth unstably between two or more alternative interpretations. objects recognized independent of rotation, translation, and scale. Figure 5.6 shows typical examples found in Gestalt psychology on visual perception providing a distinguished explanation of human perform figureground segmentation to recognize the whole object from its parts . The most famous phenomena of Gestalt psychology are rubin-vase and oldlady/young-girl figure-ground segmentation shown in Fig. 5.6a, b. Human can perform segmentation-ground segmentation subconsciously to recognize either a rubin-vase or two human faces but not both simultaneously. Why? In regard to Gestalt psychology, we have inherited the ability to extract an object (from our mind) out of a scene, the object should be recognizable in our mind and the scene is not recognizable (or meaningless in context) as shown in Fig. 5.6c. The importance is that it not only demonstrated the phenomena of how human perform figure-ground segmentation, but also various object recognition problems with invariant properties in Fig. 5.6f. 5.6.2 Traditional Figure-Ground Segmentation Methods Traditional CV methods on figure-ground segmentation are mainly focused on four areas: (1) color threshold; (2) edge detection; (3) shape detection; and texture detection (Bhuyan 2019; Forsyth and Ponce 2010). Color Threshold Color threshold is based on the simple fact that a figure object should be in different color, normally from the background scene. By using color threshold and analysis methods, we can separate the figure object technically from the background scene. Figure 5.7 shows how color threshold method works to extract a scene of the colored fruits by using MATLAB color threshold toolbox (Gonzalez 2009). The Color Thresholder toolbox displays an image in the Choose a Color Space tab, with point clouds representing the image in these color spaces: RGB, HSV, and YCbCr. For color-based segmentation, select the color space that provides the best color separation. Use the mouse to rotate the point cloud representations to see how they isolate individual colors. Segmentation using Color Thresholder can be an iterative processâ€” attempts on several different color spaces to achieve a fitting segmentation. The advantages of color threshold are simple to use and understand. This method can only be applied to simple objects with unique colors but not on complex objects with complex texture. Edge Detection Edge detection (Bhuyan 2019; Channar 2020) is one of the most frequently used figure-ground segmentation techniques in computer vision. It derived from the basic concept that any figure object has its own shape and boundary (called edge ) from the surrounding scene. We can segment figure object(s) from the scene and environment by using simple edge-detection functions. Techniques frequently used include: Canny, Sobel, Prewitt, and Roberts methods. The advantages of edge-detection techniques are that they distribute many graphical and scientific project development applications as standard image processing libraries and functions such as OpenCV (Kaehler and Bradski 2016) and MATLAB (Gonzalez 2009). Figure 5.8 illustrates figure-ground segmentation using the canny edge-detection method on the famous Lena picture generated by MATLAB image processing toolbox. The major disadvantage of edge-detection method for figure-ground segmentation is that such a method is only useful in two conditions: (1) The background scene is not too complex. If it is and full of other pattens, it is easy to segment the wrong object from the background; (2) Only one or two figure object(s) appeared in the scene. In other words, if there are many figure objects in the background scene, it is difficult to segment all figure objects effectively. Shape Detection Shape detection (Bhuyan 2019; Peters 2017) method derived from the concept that figure-object should either: (1) has a well-defined shape or (2) has a completely different texture from the surrounding environment. By distinguishing these standard shapes or textures from the environment, we can segment the figure object technically from the scene. Frequently used shape detection techniques include contour, elastic graph, and snake tracking methods . Simply speaking, contouring method borrows the concept of contour drawing for landscapes and mountains by fitting some regular shapes, e.g. triangles, square, rectangle, or polygons into the scene to extract figure object(s). Snake and elastic graph tracking methods extend the idea by using a snake or elastic graphs (is, in fact, a set of mathematical formulae) to trace the contours and extract figure object(s). Again, these methods are frequently used and now become a standard library for many image processing and data mining tools such as MATLAB, OpenCV even Python tools (Solem 2012). Figure 5.9 demonstrates how a snake model works to extract figure object from the clustered scene with a variety of objects include: a human at the foreground, a monitor and PC at the back. Also, there is a bird at the right-bottom corner. Can you spot it ?  Texture detection (Bhuyan 2019) method derived from the concept that the figure object should have a completely different texture as compared with its surrounding environment. By filtering-out the background by texture analysis, we can technically extract figure object(s) from the scene accordingly. Frequently used texture analysis schemes are texture filter using various filtering techniques such as linear filtering, anisotropic filtering, and mipmap filtering techniques that integrated with several image processing tools such as MATLAB and OpenGL. In fact, the most popular texture filtering method used commercially is Gabor Filter to signal processing and noise filtering applications. Figure 5.10 illustrates an example of the texture-based object, e.g. a dog segmentation using Gabor Filter performed by MATLAB image processing toolbox (Gonzalez 2009). As said, texture-detection method is good when either the object or background scene has a completely different texture. If both background and figure object do not have well-defined texture, they will deteriorate the performance of the texture filter significantly. 5.6.3 Neural Oscillators in Our Brain In the previous chapter, we studied the biological neural network of our brain. Current neurophysiology advises us that all neurons of our brain exist in the state of oscillations , chaotic oscillation to be exact. The latest neuroscience studies even reveal that our thinking , learning, and possibly vision processing is achieved in the form of neural oscillations (Lee 2006a).Can we see them? The answer is: We observe and realize their existence long ago but not aware of how important they are. The most common example is called brain wavesâ€”the EEG (electroencephalogram) patterns of our brain at different stages of our daily activities which are collective neural oscillation patterns of neurons inside our brain. There is a total of five brain waves types (Someren et al. 2011) appear in different stages of our awareness as shown in Fig. 5.11: Beta wave (16â€“30 Hz)â€”awake, conscious state. Gamma wave (31â€“100 Hz)â€”insight and peak focus conscious state. Alpha wave (8â€“15 Hz)â€”relaxed, calm, lucid dream (but not thinking). Theta wave (4â€“7 Hz)â€”REM dream state, meditation, deep relaxation. Delta wave (0.1â€“3 Hz)â€”deep, dreamless sleep. Additionally, neuroscientists today even believe that such neural oscillation exists in the form of chaotic oscillation. They not only exist in brain but also found in all our five senses of perception (Arbib et al. 1991): Visual nerveâ€”eye (vision) Olfactory nerveâ€”nose (smell) Auditory nerveâ€”ear (sound) Gustatory nervesâ€”tongue (taste) Somatosensory nervesâ€”skin (touch) Figure 5.12 illustrates the neural structure of visual processing. 5.6.4 Figure-Ground Segmentation Using Neuro-oscillators Current neurophysiological evidence revealed that the neural interaction of our visual process is a typical photo-electrical effect between light wave (photons) and neurons inside our optic nerve in the form of chaotic neural oscillations . The frequency of these oscillations is in the range of 40 Hz (i.e. Gamma wave) and differed from the periodic activation induced by grating, suggesting that the oscillations and their synchronization were due to internal neuronal interactions, providing extensive evidence of the functional role of gamma oscillations in visual perception and feature binding (Basar 2007). By using this new theory, neuroscientists believe that how we can segment a figure object from a complex scene in a just split-second (maybe less than 1 s) is not because we use traditional edge-detection or texture-detection schemes, but instead are rapid and simultaneous neural oscillations once visual neurons contact with visual stimulus and took few time-cycles only for the figure object to popup onto your conscious mind (Lee 2003, 2006a). The problem is, how can we construct such a powerful neural oscillator? After over 5 years of research and numerous tests, the author created an ideal chaotic neural oscillator, now known as Lee-oscillator in 2004, and published in two major neural network journals IEEE Transactions on Neural Networks (Lee 2004), for the introduction of Lee-oscillator with its transient chaotic behavior; and Journal of Neural Networks (Lee 2006a), for the exploration of Lee-oscillator on the stimulation of human visual perception with progressive memory recalling mechanisms . Figure 5.13 depicts the neural model of Lee-oscillator. Basically, Lee-oscillator consists of 4 neural elements: E, I,  , and L which corresponds to excitatory, inhibitory, input, and output neurons , where e1, e2, i1, and i2 are the weights and S(t) is the external input stimulus. Being an analogue of the classical Hopfield network as an auto-associator, a transient chaotic auto-associative network based on Lee oscillators as its constituting neuron elements can be used to provide an innovative progressive memory association and recalling scheme (Lee 2004, 2006a) to expand how human can recall memory and to explain the important phenomenaâ€”Gestalt visual psycholog y on figure-ground segmentation. The direct adoption of Lee-oscillator is based on a simple 2D single-layered neural population analogous to a classical Hopfield network studied in the previous chapter. A collection of Lee oscillators as basic neural elements is constructed to form the Lee-associator (Lee 2006b). Figure 5.14 illustrates a schematic diagram of the Lee-associator. The interactions among constituent neurons of Lee oscillators in this network can act as an auto-associator in the presence of query patterns that are treated as external input stimuli, in analogy to the classical Hopfield network. However, in contrast to these classical models, the proposed Leeassociator provide a change in neural dynamics (from a chaotic to a stable state transition) when pattern association occurs with remarkable progressive memory construction (recalling) and Gestalt visual psychology on figureground segmentation. Figure 5.15 shows how Lee-associator uses chaotic neural oscillation method to perform fast figure-ground segmentation on the famous rubin-vase test of Gestalt visual psychology (Lee 2006b). The figure on the left showed a standard visual stimulus with the complete rubin-vase object. As shown in the oscillation chart (left), within 50 timecycle, Lee-associator only took 6 time-steps to complete the vase object extraction. In terms of gamma wave with the visual perception of 40 Hz, 6 time-steps of figure-ground segmentation rate corresponded to 6/40 = 0.15 s, which are evenly matched to human figure-ground segmentation rate on rubin-vase experiments . Another important evidence revealed from the rubin-vase experiment (Lee, 2006a) was that the Lee-associator could truly extract either rubin-vase or two human face profiles during the experiment, mainly due to the fact that the Leeassociator performed chaotic oscillations in each test. In fact, the results could oscillate between 2 possible outcomes, alike human performance in visual perception. The figure on the right revealed another important property of Lee-associator in figure-ground segmentation with the provision of the partial shape of the figure object. As shown in experiment results, it took around 36 time-steps for Lee-associator to figure out the rubin-vase with the provision of a partial shape. From the human perspective, it corresponded to around 0.9 s for figure object extraction. In fact, chaotic neural oscillators can not only be applied to figureground segmentation, but also to other object recognition and visual tracking problems. 5.7 Objection Recognition 5.7.1 How Human Recognize Objects? Letâ€™s take a look at Fig. 5.16. What object(s) do you see? A dog, a plant, some leaves, or nothing? If you see a dog. What kind of dog it is? Is it your dog? If not, why are you so sure? As we can see, a simple picture like this can tell us a lot about how powerful human handle object vision and recognition problems (Cyganek 2013; Lee 2003). Once we see such picture, only within a split-second, we can perform consciously or even subconsciously all these vision processes in seconds (or less) which include (Bhuyan 2019): 1. Figure-ground segmentation of figure objectâ€”extract the dog image from background scene. 2. Object recognitionâ€”mentally match this dog object from our memory and recognize it as a dog. 3. Knowledge acquisitionâ€”retrieve about this dog from our memory. related information and knowledge We already learnt figure-ground segmentation in the previous sections. In fact, some individuals working on image processing nevertheless believe that processes 1 and 2 are identical. Their argument is that: In terms of image processing, is it technically possible to recognize an object from a picture with the complex background? The answer is yes and no. Yes, in the sense that in terms of image processing, we can do so. But if we wish to implement CV, that is, to simulate how human visual processing and recognition process, they will be separate steps and processes. For example, when we enter a classroom with over 40 students, what we see in a split-second is not a 2D picture of the classroom with students , but possibly a classroom of many studentsâ€™ faces . Latest visual and cognitive psychology revealed that humans are particularly skillful in segment human faces for recognition. In terms of machine learning and neural networks, our brains are somehow hardwired to extract human face from a complex scene and recognize it at an astonishing speed from out of thousands of faces we came across! Once we recognize the object, human will by default subconsciously relate it to a lot of attributes which include: names, sensations, events, images even videos that are all belonged to an important concept and theory so-called ontological knowledge acquisition. We will study this in Chap. 7. First, let us take a look at how the machine recognizes objects (Lim et al. 2011). 5.7.2 Classical Object Recognition Model Over the years, there are numerous CV techniques on object recognition. However, all object recognition systems aim to solve a fundamental problem: Out of a collection of memory objects (may be thousands or millions), how to design a computer program to examine a match with a tested (or unseen) object? This is a two-step process: (1) information extraction module; (2) object matching module as shown in Fig. 5.17. Information extraction module aims to extract vital information from figure object for recognition. Object matching module derives information extracted from the figure object and compares them with all memory objects stored in the memory database in order to find the best match (within a certain threshold level), or no match if the best match cannot be found from the memory database. In that case, the figure object can be stored as a new memory object in the memory database as a new memory . In terms of object information extraction, although there are other methods and techniques developed in the past decades, they can be categorized into three main approaches (Cyganek 2013; Lee 2003): Model extraction technique. Feature extraction technique. Combined extraction technique. 5 Computer Vision 139 5.7.3 Model Extraction and Object Matching Technique Model-based extraction technique derives from the concept that every object has its own shape and construction. By modeling their shape and construction, we use their information as vectors for pattern matching with memory objects stored in object databank for object recognition. Frequently used methods range from simple polygon modeling , contour, and snake models studied in the previous sections on figure-ground segmentation. However, these methods are used to extract the object model with simple structure. For figure object such as human faces with complex shapes and distinctive features, a high-level model-based system such as elastic graph matching (EGM) method is frequently used in human facial recognition system nowadays. In addition to usual tricks to extract the facial shape (contour), there are two keys features for facial mask using EGM technique (Lee 2003): â€“ Distinctive facial points known as facial landmarks are used to create a 2D/3D graph of a human face. These facial landmarks include all vital facial points such as forehand, eyebrows, eyes, nose, cheekbones, mouth, lips, chin, etc. â€“ 2D/3D is constructed in the form of an elastic graph in order to provide invariance properties for different facial expressions so that it can recognize the same person even though with different expressions such as smiling and laughing, or other poses. Figure 5.18 shows a typical model-based extraction technique using elastic graph matching method (EGM) of a human face. In terms of object matching, it depends on the model extraction method being used. For facial mask modeling method, the elastic graph matching algorithm can be applied directly for object matching and recognition. The major advantage of modelbased extraction technique such as EGM method is that if all landmarks are well-defined, the model extraction rate and object recognition rate is quite high with up to 85â€“90% accuracy. However, if the figure object itself contains complex feature patterns, model-based extraction and object matching would not be able to apply effectively. The feature-based extraction technique is different from the model-based extraction technique. It is believed that pattern features of figure object are the key information for identification. By the extraction of pattern features and compared with the objects stored in the object database, we could perform object recognition effectively. What are pattern features? In fact, pattern features can be a range from low-level features such as object color or color histogram, texture patterns studied in the previous section, to high-level features extracted by algorithms (programs) such as Gabor features , or Gabor wavelets used in human face feature extraction scheme (Lee 2003; Nixon and Aguado 2019). Figure 5.19 shows how feature-based extraction is used on human face feature extraction. In this example, we used Gabor wavelets to extract high-level facial features from 39 facial landmarks of a human face. What is wavelet ? Why it is so powerful? The concept is simple. Wavelet is a kind of localize wavefunction with limited length to model and represent a feature point as multidimensional feature vectors . If we extract wavelet features of 39 facial landmarks of a human face, it becomes a digital ID with 39 attribute vectors like our fingerprint. Gabor wavelets are used to extract feature vectors with over 100â€“150 feature points in a typical fingerprint in many fingerprint recognition systems nowadays. Owing to its reliability and high accuracy, feature-based facial landmark extraction and human face identification system are used by government agencies to identify potential suspects and terrorists over decades, and are frequently used by many governments and commercial faculties for biometric-based entry and security control. However, the accuracy depends highly on the correct identification of feature landmarks. If feature landmarks cannot be clearly defined, or even not exist, it would not be able to apply. 5.7.5 Combine Extraction and Object Matching Technique In short, the combined extraction technique is an integration of model and feature extraction techniques . It is frequently used in real-time human face recognition system in many governments and public facilities such as airports and train stations for entry authentication and access control. The combination of model extraction technique is a frequently used method using elastic graph matching (EGM) method and feature extraction technique with Gabor wavelet feature extraction method on human face recognition (Lee 2003). As mentioned, the EGM method is good with object matching by using its inherited elastic graph property. Therefore, it can be used as the first step to mask the human face and identify the 39 facial landmarks. The intrinsic problem of feature-based extraction technique would be solved automatically for correct facial landmark positions identification. Once these facial landmarks are clearly located, then Gabor wavelets feature extraction techFigure 5.20 shows the combined extraction technique using EGM + Gabor niques can be applied to extract all wavelet features of the 39 facial landmarks. wavelets on human faces. One might ask, why donâ€™t we use the combined methods at the very beginning? The truth is, to build a real-time facial recognition system, says security and entry control in an airport, the average facial recognition processing time is a critical issue. In terms of object recognition speed, feature extraction is not a major issue. However, the elastic graph matching method is an intensive computational task. But thanks to the advance computer technology, big data development, and cloud computing systems; the overall real-time facial mask and feature extraction speed improved substantially in the past 10 years. Together with powerful storage and computational capacity of the facial database stored in a cloud system, real-time facial recognition system support over thousands or up to millions of users become biometric-based entry control and security systems. 5.7.6 Objection Recognition Using Neural Oscillators We had studied how neural oscillators (Lee oscillators) resolve Gestalt visual perception for the extraction of figure object effortlessly (Lee 2004, 2006a) in the previous section on figure-ground segmentation. Can neural oscillators be applied to object recognition? The answer is definitely yes . Besides the resolution of Gestalt visual perception on figure-ground segmentation of rubin-vase experiment presented in the original paper of Lee-associator (Lee 2006b), an important experiment to demonstrate how Lee-associator can be applied to complex object such as human face recognition. In the test, the author adopted the Yale University facial database (set A) which contained facial images of over 3000 human faces, each individual contains 10â€“15 poses from different views and facial expressions including frontal, side views, gimmick, and occluded faces as in Fig. 5.21a. Figure 5.21b depicts sample facial patterns from the database and progressive memory recalling (PMR) of the Lee-associator on recalling facial 5 Computer Vision 143 (a) Sample sequence facial database from Yale University (b) A sample sequence of a progressive facial pattern recall patterns (Lee 2006b). As one can see, it is different from traditional mode extraction or feature extraction and object recognition scheme. Lee-associator demonstrates a different way of object recognition method by some sort of memory recalling scheme, from complete noise pattern to reconstruct the correct human face stored in memory storage that resemble how human recall a human face from own memory instead of algorithmic matching and distance evaluation in classical computer vision methods. In terms of object recognition rate, Lee-associator took around 20 time-steps to recall a correct human face. By adopting humanâ€™s thinking and perception conscious stages with Gamma brain wave of around 40 Hz, 20 time-steps corresponded to around 0.5 s for success matching, which was quite sensible in real-life scenario to recall a strangerâ€™s face from our memory. The research of neural oscillators on CV was, in fact, only the beginning. There had been other research being conducted at different areas ranging from object recognition and recalling, to see how we interrelate different ideas and concepts inside our mindsâ€”ontolog y and knowledge base to be studied in Chap. 7. 5.8 3D & VR Modelling 5.8.1 VR and Shared Consciousness What is the world we see? Is it a true reality, or a one we imagine and create by our minds? The first time the author came across this problem was heard from the story about Platoâ€™s Allegory of the Cave in high school (Plato 2017). In this allegory, humans are only prisoners blinded by own mind as in Fig. 5.22. The world we see and live is a projection of the world. It is so real and touchable that we believe it to be the true world and called it the reality . The author was fairly puzzled by this idea at the time until the research on AI and robotic vision in 1997. From hia Ph.D. study on AI-based object recognition to implement own designed CV system on robotic vision, it came up with an interesting question . To allow robots see , navigate, and interact with the surrounding world, only figure-ground segmentation and object recognition were not enough. The first thing we need is to construct a reality (or virtual reality, VR we called nowadays) for the robot to live in, to navigate, and to interact , like what we play with the 3D/VR adventure games. From robotâ€™s perspective, because VR is part of the construction of the complete robotic system, the robot has no way to differentiate whether it is the true reality or not, as Plato mentioned in his allegory of prisoners inside the cave. Take a step further, if the world we see is only a VR, how about our worlds we all interact? Are they the same reality, or each of us has our own reality? This problem seems to be somewhat philosophic, but if we have experiences in playing multiple player VR-based adventure game, this would not be a problem. We are represented by our avatars inside the VR world (Guazzaroni and Pillai 2019). This VR world is a construction or shared consciousness we live and interact with each other as in Fig. 5.23, like what we saw in remarkable sci-fi movies such as Matrix and Avatar . The question is, how can we construct such a 3D & VR world? 5.8.2 3D Modelling Technology in Computer Vision To construct a VR world, the first step is to tackle 3D modeling problem â€“ how to build 3D objects models appeared in the VR world? (Guazzaroni and Pillai 2019). This is, in fact, one of the passionate problems in CV and AI technology, not only for academic and research purpose; but also critical for commercial and industrial use ranging from 3D movie production, 3D/VR games design to medical applications such as dentist and surgical robots which is an important component for intelligent health systems to be studied in the next part of this book. Over the past 30 years, there had been many methods and technologies proposed to build 3D models which can be categorized into three main types (WÃ¶hler 2012): Polygonal modeling â€”points in 3D space, called vertices , are connected by line segments to form a polygon mesh. However, polygons are planar and Curve modeling â€”a 3D modelling method that relies on curves to generate can only approximate curved surfaces by using numerous polygons. surface geometry and influenced by weighted control points. Curve modelling can either be parametric (i.e. based on geometric and functional parameters) or freeform (see freeform surface modelling) and rely on nonuniform rational B-splines to describe surface forms. This method Digital sculpting â€”also known as sculpt modeling or 3D sculpting , is a new is also popular in 3D printing. method to use software that offers tools to push, pull, smooth, grab, pinch or otherwise manipulate a digital object as if it were made from a real-life substance such as clay. How about if we want to digitize and model a real 3D object (a human actor) and try to track his/her motion? Can we do that? The answer is definitely yes and frequently used in film and VR game industry in the past 20 years. The concept is simple as shown in Fig. 5.24. To construct a 3D human object model and perform motion tracking, what we need is to use over 50 video cameras and surround the human object. By doing so, we use 50 2D video pictures from different perspectives (for each frame of the video) to recreate a 3D model of the human object. Also, trackers (in white) are placed onto the joints of the human skeleton to track human object precise motions as shown. The truth is: Almost all 3D/VR movies produced in Hollywood in the past 20 years used the research technology to produce true 3D motion and Matrix was the first movie applied in commercial use (Guazzaroni and Pillai 2019). 5.8.3 3D from VR to AR Once we have the knowledge and techniques on how to model a 3D object, our next challenge is to construct virtual reality (VR). Virtual reality means creating immersive, computer-generated environments that are so convincing for users to react the same way as they would in real-life. Figure 5.25a shows VR technology in a simulation city. The idea is to block out sensory input from outside and use visual and auditory cues to make the virtual world seem more real (Guazzaroni and Pillai 2019). To achieve these, a true VR system should fulfill the following requirements: 1. Convincible : A true VR world so convincible that we (the person participants in real-world) can hardly differentiate. 2. Interactive : If we move around inside the VR world, all surrounding objects and environment should move with us seamlessly, so that we can interact with the environment instantaneously without any time delay. 3. Real-time 3D-simulation: It is one of the most challenging parts in VR technology. Thanks to todaysâ€™ computing technology together with the latest 3D modeling technology studied previously in the previous section, real-time 3D-simulation is not a dream anymore. 4. Explorable : A VR world needs to be huge in scope and detailed enough for us to explore. It is like playing an adventure game, a true VR world would consist of thousands or even millions of scenes for users to explore and interact, which have substantial memory and CPU capacity. 5. Immersive : To be convincible and interactive, VR needs to engage both our bodies and minds. A true VR system must replace our senses of vision, sound and even touch, taste, and smell by certain VR devices such as 3D VR glasses, head-mounted displays (HMDs), data-gloves, motion sensors, etc. Augmented reality (AR) is an interactive experience of a real-world environment where objects reside in the real-world are enhanced by computergenerated perceptual information, sometimes across multiple sensory modalities including visual, auditory, haptic, somatosensory, and olfactory (Guazzaroni and Pillai 2019). Figure 5.25b shows how AR works in a library. A true AR library should look-and-feel exactly like the real library with value-added functions and services such as interactive search as shown. 5.9 Applications of Computer Vision in Daily Activities As we can see, the enhancement of computer vision covers figure-ground segmentation and object detection; model and feature extraction; object recognition; object tracking; 3D and VR modeling, and robotic vision. It is different from the past that core technology was used on automated image analysis in many fields at most, while machine vision usually refers to a process of combining automated image analysis with other methods and technologies, to provide automated machine and robotic vision systems for industrial applications. In fact, computer vision overlaps with machine vision (MV) in many application areas significantly nowadays (Bhuyan 2019; Guazzaroni and Pillai 2019). 5 Computer Vision 149 With the advance of AI technology, both robotic vision and VR/AR become the major areas of applications in CV and AI technology (LÃ³pez et al. 2017; Bhuyan 2019; Guazzaroni and Pillai 2019). Real-world applications of computer vision include: Face detection in cameras. Pedestrians, cars, road detection in smart (self-driving) vehicles. Vehicle license plate scanners at security checkpoints. Terrain detection in drones and airplanes. Object 3D scanning to digitize objectâ€™s physical appearance. Augmented reality (AR), mixed reality (MR) or hybrid reality (HR). Vision-based inspection system for industry, i.e. oil pipeline defects. Robotic vision on space exploration at foreign terrain, i.e. Mars exploration (Fig. 5.26). CV is a key AI component in many real-world applications of our daily activities. It is functional to use at areas like intelligent campus and city such as CV + GPS-based package delivery by drones as in Fig. 5.27, which will be studied in the next part of this book. Gait recognition (GR) (Lam et al 2007; Basar 2007; BalÃ¡Å¾ia 2013) is a lesser known but a powerful biometric recognition method in addition to frequently used biometrics such as face, iris, fingerprint, and palmprint recognition. In short, GR derives from our walking manners for identification as shown in Fig. 5.28. The theory behind this recognition system is that every individual has a unique gait. It has also been a common experience that a familiar person can be recognized by his/her own gait from a distance. The increasing influence of biometrics in todayâ€™s personal recognition needs has led researchers to leverage gait recognition capabilities. It is one of the few recognition methods that can identify people from a distance and able to improve accuracy when used with other security and surveillance techniques. Carry out basic research on gait recognition and answer the following questions: 1. Why gait recognition is possible as a kind of biometric property in terms of behavior psychology? 2. Today, face and fingerprint recognition has become an industrial standard and widely used in many commercial and government facilities for security control and user authentication. Why do we still need gait recognition? 3. What are the possible application areas and scenarios of gait recognition? Suppose you are assigned to design a gait recognition security inside the airport for security control: 1. Based on the gait recognition system architecture given in Fig. 5.29, discuss and explain how each module works. 2. Based on the various component of computer vision learnt in previous sections, propose and explain various CV methods that can be applied to each functional module shown in Fig. 5.29. 3. Give two real-world examples, explain how gait recognition system can be used in an intelligent city. We discuss the concept of computer vision (CV) and explain the three major components which include figure-ground segmentation, object recognition, and 3D & VR modeling. We also introduce various traditional and latest AI technology related to CV. The aim of this chapter is to provide some basic understanding and knowledge of CV. More importantly, how such technology be applied to AI applications that are closely related to our daily activities. With the advance of AI and robotic technology, the scope and definition of CV becomes broader and overlaps with machine vision in various aspects such as robotic vision and drone technology. CV also evolved and become a cross-discipline subject not only focusing computer technology and image processing, but also in other challenging areas that include: â€“ The exploration of human vs computer vision in terms of visual psychology. â€“ Integration with deep learning schemes such as convolution neural networks (CNN) on complex object recognition and identification. â€“ Integration with AI-based data mining and pattern discovery technology such as tumor identification and diagnosis. â€“ Integration with latest 5G & GPS technology on a location-based system such as package delivery and auto-driving. CV vision becomes an essential component in numerous AI applications to cover a broad range of functional tasks, ranging from traffic surveillance, security control, user authentication to high-end AI application such as autodriving, tumor detection, AR and robotic surgery and dentist operations. Figure 5.30 illustrates a scenario of how CV is applied to auto-driving at an intelligent city. These are critical AI applications which will be explored in detail in the next part of this book. 